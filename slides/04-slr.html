<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">
<meta name="author" content="Dr.&nbsp;Cheng-Han Yu   Department of Mathematical and Statistical Sciences   Marquette University">
<title>MATH 4780 - Fall 2023 - Simple Linear Regression r fontawesome::fa("chart-line")</title>
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
<link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
<link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
<style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
<link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto.css" id="theme">
<link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
<link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
<link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
<link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
<style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
<style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="MATH 4780 - Fall 2023 - Simple Linear Regression r fontawesome::fa(&quot;chart-line&quot;)">
<meta property="og:description" content="MATH 4780 / MSSC 5780 Regression Analysis">
<meta property="og:site-name" content="MATH 4780 - Fall 2023">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-color="#447099" class="quarto-title-block center"><h1 class="title">Simple Linear Regression <svg aria-hidden="true" role="img" viewbox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M64 64c0-17.7-14.3-32-32-32S0 46.3 0 64V400c0 44.2 35.8 80 80 80H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H80c-8.8 0-16-7.2-16-16V64zm406.6 86.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L320 210.7l-57.4-57.4c-12.5-12.5-32.8-12.5-45.3 0l-112 112c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L240 221.3l57.4 57.4c12.5 12.5 32.8 12.5 45.3 0l128-128z"></path></svg>
</h1>
  <p class="subtitle">MATH 4780 / MSSC 5780 Regression Analysis</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Dr.&nbsp;Cheng-Han Yu <br> Department of Mathematical and Statistical Sciences <br> Marquette University 
</div>
</div>
</div>

</section><section><section id="model" class="title-slide slide level1 center"><h1>Model</h1>
<aside class="notes"><ul>
<li>OK. Now we are going to talk about regression in detail. We start with the simplest one, simple linear regression.</li>
<li>Although it is the simplest one, there are a lot to talk about.</li>
<li>We not only review what we have learned in intro statistics, but talk a little bit more about the properties of this model.</li>
<li>Now everybody can fit a simple linear regression, but not many people truly understand the model well.</li>
<li>Once we understand the entire idea behind it, we know how and when to use the model, we can interpret the model correctly. And we also know the limitations of the model.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="simple-linear-regression-model-population" class="slide level2"><h2>Simple Linear Regression Model (Population)</h2>
<ul>
<li>
<strong>Simple</strong>: <strong>Only one</strong> predictor <span class="math inline">\(X\)</span>.</li>
<li>
<strong>Linear</strong>: the regression function is linear, i.e., <span class="math inline">\(f(X) = \beta_0 + \beta_1 X\)</span>.</li>
</ul>
<div class="fragment">
<p>For the <span class="math inline">\(i\)</span>-th measurement in the target population, <span class="math display">\[Y_i = \beta_0 + \beta_1X_i + \epsilon_i\]</span></p>
<ul>
<li>
<span class="math inline">\(Y_i\)</span>: the <span class="math inline">\(i\)</span>-th value of the response (random) variable.</li>
<li>
<span class="math inline">\(X_i\)</span>: the <span class="math inline">\(i\)</span>-th <strong>known fixed</strong> value of the predictor.</li>
<li>
<span class="math inline">\(\epsilon_i\)</span>: the <span class="math inline">\(i\)</span>-th random error with assumption <span class="math inline">\(\epsilon_i \stackrel{iid}{\sim} N(0, \sigma^2)\)</span>. <!-- - $\beta_0$ and $\beta_1$ are model coefficients. -->
</li>
<li>
<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma^2\)</span> are <strong>fixed unknown parameters</strong> to be estimated from the training sample after we collect them.</li>
</ul>
<aside class="notes"><ul>
<li>Here is the formal Simple Linear Regression Model that describes my words mathematically.</li>
<li>
<span class="math inline">\(\epsilon_i\)</span>: the <span class="math inline">\(i\)</span>-th random error
<ul>
<li>Each <span class="math inline">\(\epsilon_i\)</span> has an identical normal distribution with mean 0 and constant variance <span class="math inline">\(\sigma^2\)</span>.</li>
<li>Any <span class="math inline">\(\epsilon_i\)</span> and <span class="math inline">\(\epsilon_j\)</span>, <span class="math inline">\(i \ne j\)</span>, are independent or uncorrelated.</li>
</ul>
</li>
<li>And this is the population Simple Linear Regression Model. Because we assume <span class="math inline">\(y\)</span> is drawn from a population distribution with some population parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma^2\)</span>.</li>
<li>Just like we assume <span class="math inline">\(Y_i \sim N(\mu, \sigma^2)\)</span> in intro stats. The only difference is that now <span class="math inline">\(Y_i\)</span> and its mean depend on the value of <span class="math inline">\(X\)</span>.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="section-1" class="slide level2"><h2></h2>
<p>When we collect data <span class="math inline">\(\{ (x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\},\)</span> <span class="math inline">\(y\)</span> is assumed drawn from a normal distribution. Its value varies around its mean <span class="math inline">\(\mu_y\)</span>.</p>

<img data-src="./images/04-slr/regression_line_data.png" style="width:85.0%" class="r-stretch quarto-figure-center"><aside class="notes"><p>Let’s see what the assumptions of the model mean, and the ideas of behind them.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="section-2" class="slide level2"><h2></h2>
<p>When we collect data <span class="math inline">\(\{ (x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\},\)</span> <span class="math inline">\(y\)</span> is assumed drawn from a normal distribution. Its value varies around its mean <span class="math inline">\(\mu_y\)</span>.</p>

<img data-src="./images/04-slr/regression_line_data_blue.png" style="width:85.0%" class="r-stretch quarto-figure-center"></section><section id="conditional-mean-of-y_i-given-a-value-of-x_i" class="slide level2"><h2>Conditional Mean of <span class="math inline">\(Y_i\)</span> given a value of <span class="math inline">\(X_i\)</span>
</h2>
<div class="columns">
<div class="column" style="width:55%;">
<p><span class="math inline">\(Y_i = \beta_0 + \beta_1X_i + \epsilon_i\)</span> <span class="math inline">\(\quad \epsilon_i \stackrel{iid}{\sim} N(0, \sigma^2)\)</span></p>
<div class="fact">
<p>For a random variable <span class="math inline">\(Z\)</span> and a constant <span class="math inline">\(c \in \mathbf{R}\)</span>, <span class="math inline">\(E(c+Z) = E(c) + E(Z) = c + E(Z)\)</span>.</p>
</div>
</div><div class="column" style="width:40%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/regression_line_red.png" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
<p><span class="math display">\[\begin{align*}
\mu_{Y_i \mid X_i} = E(Y_i \mid X_i) &amp;= E(\beta_0 + \beta_1X_i + \epsilon_i) \\
&amp;= \beta_0 + \beta_1X_i + E(\epsilon_i) \\
&amp;= \beta_0 + \beta_1X_i
\end{align*}\]</span></p>
<p>The <strong>mean response</strong> of <span class="math inline">\(Y\)</span>, <span class="math inline">\(\mu_{Y\mid X} = E(Y\mid X)\)</span>, has a <strong>straight-line</strong> relationship with <span class="math inline">\(X\)</span> given by the population regression line <span class="math display">\[\mu_{Y\mid X} = \beta_0 + \beta_1X\]</span></p>
</section><section id="conditional-variance-of-y_i-given-a-value-of-x_i" class="slide level2"><h2>Conditional Variance of <span class="math inline">\(Y_i\)</span> given a value of <span class="math inline">\(X_i\)</span>
</h2>
<div class="columns">
<div class="column" style="width:55%;">
<p><span class="math inline">\(Y_i = \beta_0 + \beta_1X_i + \epsilon_i\)</span> <span class="math inline">\(\quad \epsilon_i \stackrel{iid}{\sim} N(0, \sigma^2)\)</span></p>
<div class="fact">
<p>For a random variable <span class="math inline">\(Z\)</span> and a constant <span class="math inline">\(c \in \mathbf{R}\)</span>, <span class="math inline">\(\mathrm{Var}(c+Z) = \mathrm{Var}(Z)\)</span>.</p>
</div>
</div><div class="column" style="width:40%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/regression_line_sig.png" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
<p><span class="math display">\[\begin{align*}
\mathrm{Var}(Y_i \mid X_i) &amp;= \mathrm{Var}(\beta_0 + \beta_1X_i + \epsilon_i) \\
&amp;= \mathrm{Var}(\epsilon_i) = \sigma^2
\end{align*}\]</span> The variance of <span class="math inline">\(Y\)</span> does not depend on <span class="math inline">\(X\)</span>.</p>
<aside class="notes"><ul>
<li>The variation of Y is the same no matter what value of x is.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="conditional-distribution-of-y_i-mid-x-x_i" class="slide level2"><h2>Conditional Distribution of <span class="math inline">\(Y_i \mid X = x_i\)</span>
</h2>
<div class="columns">
<div class="column" style="width:55%;">
<p><span class="math inline">\(Y_i = \beta_0 + \beta_1X_i + \epsilon_i\)</span>; <span class="math inline">\(\quad \epsilon_i \stackrel{iid}{\sim} N(0, \sigma^2)\)</span></p>
<div class="fact">
<p>For a random variable <span class="math inline">\(Z \sim N(\mu, \sigma^2)\)</span> and a constant <span class="math inline">\(c \in \mathbf{R}\)</span>, <span class="math inline">\(c+Z \sim N(c + \mu, \sigma^2)\)</span>.</p>
</div>
</div><div class="column" style="width:40%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/regression_dist.png" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
<p><span class="math display">\[\begin{align*}
Y_i \mid X_i \stackrel{indep}{\sim} N(\beta_0 + \beta_1X_i, \sigma^2)
\end{align*}\]</span> For any fixed value of <span class="math inline">\(X_i = x\)</span>, the response <span class="math inline">\(Y_i\)</span> varies according to <span class="math inline">\(N(\mu_{Y_i\mid X_i = x}, \sigma^2)\)</span>.</p>
<div class="fragment">
<p><br></p>
<p><strong>Job</strong>: Collect data and estimate the unknown <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma^2\)</span>!</p>
<aside class="notes"><p>With the model, our first job is to collect data and estimate the unknown parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma^2\)</span>!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section></section><section><section id="parameter-estimation-and-model-fitting" class="title-slide slide level1 center"><h1>Parameter Estimation and Model Fitting</h1>

</section><section id="idea-of-fitting" class="slide level2"><h2>Idea of Fitting</h2>
<ul>
<li>Interested in <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in the <em>sample</em> regression model:</li>
</ul>
<p><span class="math display">\[\begin{align*}
y_i &amp;= f(x_i) +  \epsilon_i \\
    &amp;= \beta_0 + \beta_1~x_{i} + \epsilon_i,
\end{align*}\]</span> or</p>
<p><span class="math display">\[E(y_i \mid x_i) = \mu_{y|x_i} = \beta_0 + \beta_1~x_{i}\]</span></p>
<div class="fragment">
<ul>
<li><p>Use sample statistics <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> computed from our sample data to estimate <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p></li>
<li><p><span class="math inline">\(\hat{y}_{i} = b_0 + b_1~x_{i}\)</span> is called <strong>fitted value</strong> of <span class="math inline">\(y_i\)</span>, a point estimate of the mean <span class="math inline">\(\mu_{y|x_i}\)</span> and <span class="math inline">\(y_i\)</span> itself.</p></li>
</ul>
<!-- - $\hat{y}_{i} = b_0 + b_1~x_{i}$ predicted value --><aside class="notes"><ul>
<li>OK. once we collect the data, we have a sample regression model.</li>
<li>Here I use small x and y to represent the collected data.</li>
<li>Given this model, we’re interested in <span class="math inline">\(\beta_0\)</span> (population parameter for the intercept) and <span class="math inline">\(\beta_1\)</span> (population parameter for the slope) because once we know <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, we know the exact shape of <span class="math inline">\(f\)</span> and we know the relationship of <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>, and given any value of <span class="math inline">\(x\)</span>, we can predict its corresponding value of <span class="math inline">\(y\)</span> using the regression line <span class="math inline">\(\hat{y}_{i} = \beta_0 + \beta_1~x_{i}\)</span>.</li>
<li>But again the population parameters are unknown to us.</li>
<li><span class="math inline">\(\hat{y}_i = E(Y|X_i=x_i)\)</span></li>
<li>
<span class="math inline">\(b_0\)</span>: intercept of the sample regression line</li>
<li>
<span class="math inline">\(b_1\)</span>: slope of the sample regression line</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="fitting-a-regression-line-haty-b_0-b_1x" class="slide level2"><h2>Fitting a Regression Line <span class="math inline">\(\hat{Y} = b_0 + b_1X\)</span>
</h2>
<p>Given the training sample <span class="math inline">\(\{ (x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\},\)</span></p>
<ul>
<li>Which <em>sample</em> regression line is the <strong>best</strong>?</li>
<li>What are the <strong>best</strong> estimators <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>?</li>
</ul>

<img data-src="./images/04-slr/unnamed-chunk-7-1.png" style="width:58.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>Now suppose we already get our sample, and now we are trying to use the sample to get a sample regression line, and hopefully, the sample regression line and the population regression line are alike. look similarly.</li>
<li>So people usually ask</li>
<li>Which <em>sample</em> regression line is the <strong>best</strong>?</li>
<li>What are the <strong>best</strong> estimators <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>?</li>
<li>After all, given the data, we can generate so many different straight lines, and we need a criterion to help us determine which line is the best in some sense. Right!</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="what-does-best-mean-ordinary-least-squares-ols" class="slide level2"><h2>What does “best” mean? Ordinary Least Squares (OLS)</h2>
<!-- - Choose $b_0$ and $b_1$, or sample regression line $b_0 + b_1x$ that minimizes the **sum of squared residuals $SS_{res}$**. -->
<!-- - The **residual** $e_i = y_i - \hat{y}_i = y_i - (b_0 + b_1x_i)$ is a point estimate of $\epsilon_i$.  -->
<!-- - The sample regression line minimizes $SS_{res} = e_1^2 + e_2^2 + \dots + e_n^2 = \sum_{i = 1}^n e_i^2$. -->
<!-- $$\small{\begin{align} SS_{res} &= (y_1 - b_0 - b_1x_1)^2 + (y_2 - b_0 - b_1x_2)^2 + \dots + (y_n - b_0 - b_1x_n)^2\\ &= \sum_{i=1}^n(y_i - b_0 - b_1x_i)^2 \end{align}}$$ -->
<p>Choose the <em>best</em> <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> or the sample regression line minimizing the <strong>sum of squared residuals</strong> <span class="math display">\[SS_{res} = e_1^2 + e_2^2 + \dots + e_n^2 = \sum_{i = 1}^n e_i^2.\]</span></p>
<ul>
<li>The <strong>residual</strong> <span class="math inline">\(e_i = y_i - \hat{y}_i = y_i - (b_0 + b_1x_i)\)</span> is a point estimate of <span class="math inline">\(\epsilon_i\)</span>.</li>
</ul>
<div class="fragment">
<ul>
<li>If <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are the best estimators, plug <span class="math inline">\(e_i = y_i - (b_0 + b_1x_i)\)</span> into <span class="math inline">\(SS_{res}\)</span>, we have</li>
</ul>
<p><span class="math display">\[\begin{align} SS_{res} &amp;= (y_1 - b_0 - b_1x_1)^2 + (y_2 - b_0 - b_1x_2)^2 + \dots + (y_n - b_0 - b_1x_n)^2\\ &amp;= \sum_{i=1}^n(y_i - b_0 - b_1x_i)^2 \end{align}\]</span> that is the smallest comparing to any other <span class="math inline">\(SS_{res} = \sum_{i=1}^n(y_i - a_0 - a_1x_i)^2\)</span> that uses another pair of estimators <span class="math inline">\((a_0, a_1) \ne (b_0, b_1)\)</span>.</p>
<aside class="notes"><ul>
<li>Now the question is How do we get <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> that well estimate <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>?</li>
<li>We choose <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, or regression line <span class="math inline">\(b_0 + b_1x\)</span> that minimizes the <strong>sum of squared residuals</strong>.</li>
<li>If we define residual as <span class="math inline">\(e_i = y_i - \hat{y}_i\)</span>, then the sum of squared residuals is <span class="math inline">\(\sum_{i = 1}^n e_i^2\)</span>.</li>
<li>And this approach that estimates the population parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> or the population regression line is called Ordinary Least Squares method.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="visualizing-residuals" class="slide level2"><h2>Visualizing Residuals</h2>

<img data-src="./images/04-slr/unnamed-chunk-8-1.png" style="width:85.0%" class="r-stretch quarto-figure-center"><aside class="notes"><p>That’s see the idea of Ordinary Least Squares visually. Here just showed the data. - Later we will work on the data set together. <!-- - Do you see why some points are darker than some others? --> <!-- - A darker point means that there are several identical (x, y) pairs, or replicates in the data set. --></p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="visualizing-residuals-cont." class="slide level2"><h2>Visualizing Residuals (cont.)</h2>

<img data-src="./images/04-slr/unnamed-chunk-9-1.png" style="width:85.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>All right, with the data, this figure also shows the least squares regression line, and the fitted value of <span class="math inline">\(y\)</span> for each <span class="math inline">\(x\)</span> in the training data, which are those red points.</li>
<li>The fitted values of y are right on the regression line.</li>
<li>Now the question is, how do we find this line?</li>
<li>Given a line, we can have predicted values of y, right?</li>
<li>Then what is residual on the plot? The residual will be the difference between the true observation y and the fitted value of y given any value of x.</li>
<li>So a residual in the plot will be a vertical bar at the value of x with two ends of the bar <span class="math inline">\(y\)</span> and <span class="math inline">\(\hat{y}\)</span>, right?</li>
<li>(Show on board)</li>
<li>(add <span class="math inline">\(y_i = b_0+b_1x_i\)</span> and residual line)</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="visualizing-residuals-cont.-1" class="slide level2"><h2>Visualizing Residuals (cont.)</h2>

<img data-src="./images/04-slr/unnamed-chunk-10-1.png" style="width:85.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>Here shows all the residuals in vertical bars.</li>
<li>least squares line is the line such that the sum of all the squared residuals is minimized.</li>
<li>Why we square the residuals?</li>
<li>It’s mathematically more convenient.</li>
<li>Squaring emphasizes larger differences</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="least-squares-estimates-lse" class="slide level2"><h2>Least Squares Estimates (LSE)</h2>
<ul>
<li>The least squares approach choose <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> that minimize the <span class="math inline">\(SS_{res}\)</span>, i.e., <span class="math display">\[(b_0, b_1) = \arg\min_{\alpha_0, \alpha_1} \sum_{i=1}^n(y_i - \alpha_0 - \alpha_1x_i)^2\]</span>
</li>
</ul>
<div class="fragment">
<p>Take derivative w.r.t. <span class="math inline">\(\alpha_0\)</span> and <span class="math inline">\(\alpha_1\)</span>, setting both equal to zero: <span class="math display">\[\left.\frac{\partial SS_{res}}{\partial\alpha_0}\right\vert_{b_0, b_1} = \left.\sum_{i=1}^n\frac{\partial (y_i - \alpha_0 - \alpha_1x_i)^2}{\partial\alpha_0}\right\vert_{b_0, b_1} = -2 \sum_{i=1}^n(y_i - b_0 - b_1x_i) = 0\]</span> <span class="math display">\[\left. \frac{\partial SS_{res}}{\partial\alpha_1}\right\vert_{b_0, b_1} = \left.\sum_{i=1}^n\frac{\partial (y_i - \alpha_0 - \alpha_1x_i)^2}{\partial\alpha_1}\right\vert_{b_0, b_1} = -2 \sum_{i=1}^nx_i(y_i - b_0 - b_1x_i) = 0\]</span> The two equations are called the <strong>normal equations</strong>.</p>
</div>
</section><section id="least-squares-estimates-solve-for-alpha_0-and-alpha_1" class="slide level2"><h2>Least Squares Estimates: Solve for <span class="math inline">\(\alpha_0\)</span> and <span class="math inline">\(\alpha_1\)</span>
</h2>
<ul>
<li>Solve for <span class="math inline">\(\alpha_0\)</span> given <span class="math inline">\(b_1\)</span>:</li>
</ul>
<p><span class="math display">\[ \color{red}{b_0 = \overline{y} - b_1\overline{x}}\]</span></p>
<div class="fragment">
<ul>
<li>Solve for <span class="math inline">\(\alpha_1\)</span> given <span class="math inline">\(\color{red}{b_0 = \overline{y} - b_1\overline{x}}\)</span>:</li>
</ul>
<!-- $$\sum_{i=1}^nx_iy_i - (\overline{y} - b_1\overline{x})n\overline{x} - b_1\sum_{i=1}^nx_i^2 = 0.$$ --><p><span class="math display">\[\color{red}{b_1 = \frac{\sum_{i=1}^n(x_i - \overline{x})(y_i - \overline{y})}{\sum_{i=1}^n(x_i - \overline{x})^2} = \frac{S_{xy}}{S_{xx}} = r \frac{\sqrt{S_{yy}}}{\sqrt{S_{xx}}}},\]</span> where <span class="math inline">\(S_{xx} = \sum_{i=1}^n(x_i - \overline{x})^2\)</span>, <span class="math inline">\(S_{yy} = \sum_{i=1}^n(y_i - \overline{y})^2\)</span>, <span class="math inline">\(S_{xy} = \sum_{i=1}^n(x_i - \overline{x})(y_i - \overline{y})\)</span>, and <span class="math inline">\(r\)</span> is the sample correlation coefficient between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p>
</div>
<div class="fragment">
<div class="question">
<p>What can we learn from the formula of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>?</p>
</div>
<aside class="notes"><ul>
<li>The LS regression line passes through the centroid.</li>
<li>
<span class="math inline">\(b_1\)</span> is kinda like a scaled covariance of X and Y.</li>
<li>
<span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are correlated.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="r-lab-highway-mpg-hwy-vs.-displacement-displ" class="slide level2"><h2>
<span class="pink">R Lab</span> Highway MPG <code>hwy</code> vs.&nbsp;Displacement <code>displ</code>
</h2>
<ul>
<li>Data set: <code>mpg</code> in <code>ggplot2</code> package.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="do">## install.packages("ggplot2")</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-3"><a href="#cb1-3"></a>mpg</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 234 × 11
  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class 
  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 
1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa…
2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa…
3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa…
4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa…
5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compa…
6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p     compa…
# ℹ 228 more rows</code></pre>
</div>
</div>
<aside class="notes"><ul>
<li>OK. I think we all learn what a linear regression is, and it’s time to see how to do a real data analysis using R.</li>
<li>The data set we use is stored in the ggplot2 package.</li>
<li>In order to get access to the data, you have to install and load the package into your R session.</li>
<li>You can use the command install.packages(“ggplot2”) and library(ggplot2) to do so.</li>
<li>Once you are done. Simply type the data set’s name mpg on your R console, it will print the data set.</li>
<li>It is of type tibble, basically a new version of data frame.</li>
<li>There are 234 different cars with 11 variables.</li>
<li>In this example, we are going to use the two variables, <code>hwy</code> which is highway miles per gallon and <code>displ</code>, the size of engine displacement.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="r-lab-scatter-plot" class="slide level2"><h2>
<span class="pink">R Lab</span> Scatter Plot</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="fu">plot</span>(<span class="at">x =</span> mpg<span class="sc">$</span>displ, <span class="at">y =</span> mpg<span class="sc">$</span>hwy, <span class="at">las =</span> <span class="dv">1</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">col =</span> <span class="st">"navy"</span>, <span class="at">cex =</span> <span class="fl">0.5</span>,</span>
<span id="cb3-2"><a href="#cb3-2"></a>     <span class="at">xlab =</span> <span class="st">"Displacement (litres)"</span>, <span class="at">ylab =</span> <span class="st">"Highway MPG"</span>,</span>
<span id="cb3-3"><a href="#cb3-3"></a>     <span class="at">main =</span> <span class="st">"Highway MPG vs. Engine Displacement (litres)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="./images/04-slr/unnamed-chunk-12-1.png" style="width:68.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>Usually, when we get data, the first thing is plotting your data, doing some exploratory data analysis, and see if there is useful information out there that may help us build an appropriate model.</li>
<li>To make a scatter plot, we can simply use the plot() function, and put displ in x axis and hwy in the y axis.</li>
<li>To grab a variable or a column of a data frame, we can use the dollar sign, the same way as a list extracting an element.</li>
<li>The rest of arguments are optional, they are just used to decorate your plot. You can generate a plot without specifying any of them.</li>
<li>And because it seems to a linear trend downwards. We could fit a simple linear regression to the data. Right</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="r-lab-fit-simple-linear-regression" class="slide level2"><h2>
<span class="pink">R Lab</span> Fit Simple Linear Regression</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a>(reg_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> hwy <span class="sc">~</span> displ, <span class="at">data =</span> mpg))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = hwy ~ displ, data = mpg)

Coefficients:
(Intercept)        displ  
      35.70        -3.53  </code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="fu">typeof</span>(reg_fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "list"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="do">## use $ to extract an element of a list</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>reg_fit<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)       displ 
      35.70       -3.53 </code></pre>
</div>
</div>
<div class="fragment">
<ul>
<li><p><span class="math inline">\(\widehat{hwy}_{i} = b_0 + b_1 \times displ_{i} = 35.698 -3.531 \times displ_{i}\)</span></p></li>
<li><p><span class="math inline">\(b_1\)</span>: For one unit (litre) increase of the displacement, we expect the highway MPG to be decreased, <span class="red">on average</span>, by 3.5 miles.</p></li>
</ul>
<aside class="notes"><ul>
<li>In R, to fit a linear regression model, it cannot be easier.</li>
<li>We just need to use the command lm(). We put a formula in the function, y ~ x, and let R know which data set you are considering.</li>
<li>That’s it. And I save the fitted result in an object called reg_fit.</li>
<li>You can see lm() function returns a list.</li>
<li>We can grab the coefficient estimates this way.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="r-lab-fitted-values" class="slide level2"><h2>
<span class="pink">R Lab</span> Fitted Values</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="do">## all elements in reg_fit</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="fu">names</span>(reg_fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "coefficients"  "residuals"     "effects"       "rank"         
 [5] "fitted.values" "assign"        "qr"            "df.residual"  
 [9] "xlevels"       "call"          "terms"         "model"        </code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>mpg<span class="sc">$</span>hwy[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 29 29 31 30 26</code></pre>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a><span class="do">## the first 20 fitted value y_hat</span></span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="fu">head</span>(reg_fit<span class="sc">$</span>fitted.values, <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   1    2    3    4    5 
29.3 29.3 28.6 28.6 25.8 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>mpg<span class="sc">$</span>displ[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.8 1.8 2.0 2.0 2.8</code></pre>
</div>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a><span class="fu">length</span>(reg_fit<span class="sc">$</span>fitted.values)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 234</code></pre>
</div>
</div>
<aside class="notes"><ul>
<li>If you wanna see what information is contained in the fitted result, you can check all of its elements by names because each element here has a name.</li>
<li>To get the fitted value of <span class="math inline">\(y\)</span>, simply type reg_fit$fitted.values</li>
<li>It will show all 234 fitted values of y for each given value of x.</li>
<li>Here I just show the first 20 fitted values, and their corresponding value of x.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="r-lab-add-a-regression-line" class="slide level2"><h2>
<span class="pink">R Lab</span> Add a Regression Line</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a><span class="fu">plot</span>(<span class="at">x =</span> mpg<span class="sc">$</span>displ, <span class="at">y =</span> mpg<span class="sc">$</span>hwy, <span class="at">las =</span> <span class="dv">1</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">col =</span> <span class="st">"navy"</span>, <span class="at">cex =</span> <span class="fl">0.5</span>,</span>
<span id="cb20-2"><a href="#cb20-2"></a>     <span class="at">xlab =</span> <span class="st">"Displacement (litres)"</span>, <span class="at">ylab =</span> <span class="st">"Highway MPG"</span>,</span>
<span id="cb20-3"><a href="#cb20-3"></a>     <span class="at">main =</span> <span class="st">"Highway MPG vs. Engine Displacement (litres)"</span>)</span>
<span id="cb20-4"><a href="#cb20-4"></a><span class="fu">abline</span>(reg_fit, <span class="at">col =</span> <span class="st">"#FFCC00"</span>, <span class="at">lwd =</span> <span class="dv">3</span>)  <span class="co">#&lt;&lt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="./images/04-slr/unnamed-chunk-15-1.png" style="width:65.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>How do we add a regression line on a scatter plot, very simple in R.</li>
<li>we just use the abline() function right after the scatter plot we created.</li>
<li>We can put the entire fitted result in the abline() function. The function will look for the intercept and slope itself and add the line onto the scatter plot.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="properties-of-least-squares-fit" class="slide level2"><h2>Properties of Least Squares Fit</h2>
<p><span style="color:#DE3163"> Both <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are <strong>linear combinations</strong> of <span class="math inline">\(y_1, \dots, y_n\)</span>. </span></p>
<ul>
<li>
<span class="math inline">\(S_{xy} = \sum_{i=1}^n(x_i - \overline{x})(y_i - \overline{y}) = \sum_{i=1}^n(x_i - \overline{x})y_i\)</span> <span class="math display">\[b_1 = \frac{S_{xy}}{S_{xx}} = \frac{\sum_{i=1}^n(x_i - \overline{x})y_i}{\sum_{i=1}^n(x_i - \overline{x})^2} = \sum_{i=1}^nc_iy_i,\]</span> where <span class="math inline">\(c_i = \frac{(x_i - \overline{x})}{S_{xx}}\)</span>.</li>
</ul>
<aside class="notes"><p><span class="math inline">\(b_0 = \overline{y} - b_1\overline{x}\)</span> <span class="math inline">\(b_1 = \frac{\sum_{i=1}^n(x_i - \overline{x})(y_i - \overline{y})}{\sum_{i=1}^n(x_i - \overline{x})^2} := \frac{S_{xy}}{S_{xx}}\)</span> - if <span class="math inline">\(x_i = \overline{x}\)</span>, its <span class="math inline">\(y_i\)</span> has no contribution on <span class="math inline">\(b_1\)</span>. - the sample regression line always pass through the center of x and y. - It is points away from the center determine the slope</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside><div class="fragment">
<div class="question">
<ul>
<li><span class="math inline">\(\sum_{i=1}^n c_i = ?\)</span></li>
<li><span class="math inline">\(\sum_{i=1}^n c_ix_i = ?\)</span></li>
</ul>
</div>
</div>
</section><section id="properties-of-least-squares-fit-1" class="slide level2"><h2>Properties of Least Squares Fit</h2>
<p><span style="color:#DE3163"> Therefore, <span class="math inline">\(\hat{y}_i\)</span> is a <strong>linear combination</strong> of <span class="math inline">\(y_1, \dots, y_n\)</span>!</span></p>
<ul>
<li>
<span class="math inline">\(b_0 = \overline{y} - b_1~\overline{x}\)</span> and <span class="math inline">\(b_1 = \sum_{j=1}^n c_j y_j\)</span>
</li>
</ul>
<p><span class="math display">\[\begin{align} \hat{y}_i &amp;= b_0 + b_1 ~x_i \\&amp;= \overline{y} - b_1~\overline{x} + x_i\sum_{j=1}^n c_j y_j \\&amp;= \cdots \\&amp;= \sum_{j=1}^nh_{ij}y_j \\&amp;= h_{i1}y_1 + h_{i2}y_2 + \cdots + h_{in}y_n\end{align}\]</span> where <span class="math inline">\(h_{ij} = \frac{1}{n} + \frac{(x_i-\overline{x})(x_j-\overline{x})}{S_{xx}}.\)</span></p>
<div class="alert">
<p>If <span class="math inline">\(h_{ij}\)</span> is large, the <span class="math inline">\(j\)</span>th case can have substantial impact on the <span class="math inline">\(i\)</span>th fitted value.</p>
</div>
<aside class="notes"><p><span class="math inline">\(h_{ij}\)</span> captures the extent to which <span class="math inline">\(y_j\)</span> can affect <span class="math inline">\(\hat{y}_i\)</span>: - if x_i = x_bar, y_hat = y_bar - <strong>hat value</strong> plays a important role in regression - For every fitted value, we use info from the all data points, and their influence is determined by their location comparing to the <span class="math inline">\(\bar{x}\)</span>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="properties-of-least-squares-fit-2" class="slide level2"><h2>Properties of Least Squares Fit</h2>
<div class="alert">
<p>Responses <span class="math inline">\(\{y_i\}_{i=1}^n\)</span> are random variables <em>before</em> we actually collect them. So are <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>.</p>
</div>
<div class="fragment">
<p><span style="color:#DE3163"> <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are <strong>unbiased estimators</strong> for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, respectively, i.e., <span class="math inline">\(E(b_0) = \beta_0\)</span>, <span class="math inline">\(E(b_1) = \beta_1\)</span>. </span></p>
</div>
<div class="fragment">
<div class="tip">
<p>For random variables <span class="math inline">\(Z_1, \dots, Z_n\)</span> and constants <span class="math inline">\(c_1, \dots, c_n \in \mathbf{R}\)</span>, <span class="math inline">\(E(c_1Z_1 + \dots +c_nZ_n) = c_1E(Z_1) + \dots + c_nE(Z_n)\)</span></p>
</div>
</div>
<div class="fragment">
<p><span class="math display">\[\begin{align*}
E(b_1) &amp;= E\left( \sum_{i=1}^n c_iy_i\right) = \sum_{i=1}^n c_i E(y_i) = \sum_{i=1}^n c_i (\beta_0+\beta_1x_i) \\
&amp;= \beta_0 \sum_{i=1}^n c_i+ \beta_1\sum_{i=1}^n c_ix_i = \beta_1
\end{align*}\]</span></p>
<aside class="notes"><ul>
<li>You can do <span class="math inline">\(E(b_0)\)</span>
</li>
<li>We don’t know the true value of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, but if we were able to collect our data set many times, and get lots of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> estimates, then the average of those <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> will be very close to the unknown <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, which is quite nice. Right.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="properties-of-least-squares-fit-3" class="slide level2"><h2>Properties of Least Squares Fit</h2>
<ul>
<li>
<strong>Gauss-Markov Theorem</strong>: <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are <strong>best linear unbiased estimators (BLUEs)</strong>.</li>
<li>
<span style="color:#DE3163"> <strong>Linear</strong> </span>: linear combinations of <span class="math inline">\(y_i\)</span>
</li>
<li>
<span style="color:#DE3163"> <strong>Unbiased</strong> </span>: <span class="math inline">\(E(b_0) = \beta_0\)</span>, <span class="math inline">\(E(b_1) = \beta_1\)</span>
</li>
<li>
<span style="color:#DE3163"> <strong>Best</strong> </span>: <strong>minimum variance</strong> ‼️</li>
</ul>
<div class="fragment">
<div class="tip">
<p>For <em>independent</em> random variables <span class="math inline">\(Z_1, \dots, Z_n\)</span> and constants <span class="math inline">\(c_1, \dots, c_n \in \mathbf{R}\)</span>, <span class="math inline">\(\mathrm{Var}(c_1Z_1 + \dots +c_nZ_n) = c_1^2\mathrm{Var}(Z_1) + \dots + c_n^2\mathrm{Var}(Z_n)\)</span></p>
</div>
</div>
<div class="fragment">
<p><span class="math display">\[\begin{align*}
\mathrm{Var}(b_1) &amp;= \mathrm{Var}\left( \sum_{i=1}^n c_iy_i\right) = \sum_{i=1}^n c_i^2 \mathrm{Var}(y_i) = \sigma^2\sum_{i=1}^n c_i^2 = \frac{\sigma^2\sum_{i=1}^n (x_i - \overline{x})^2}{S_{xx}^2} = \frac{\sigma^2}{S_{xx}}
\end{align*}\]</span></p>
</div>
<div class="fragment">
<ul>
<li>😎 <em>LSEs are unbiased and have minimum variance when compared with all other unbiased estimators that are linear combo of <span class="math inline">\(y_i\)</span></em>. 👍 👍</li>
</ul>
<aside class="notes"><ul>
<li>Finally, we have this famous Gauss-Markov Theorem saying <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are <strong>best linear unbiased estimators (BLUEs)</strong>
</li>
<li>Minimum variance is a excellent property.</li>
<li>Every time we collect a new data set, we will get the new <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, right?</li>
<li>We know <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> vary with data. But the theorem tells us that their variation is minimal comparing to other estimators.</li>
<li>So this minimizes our uncertainty about <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>
</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="properties-of-least-squares-fit-4" class="slide level2"><h2>Properties of Least Squares Fit</h2>
<p>👉 <em>Sum of residuals is zero.</em></p>
<p><span class="math display">\[\scriptstyle \sum_{i=1}^n(y_i - \hat{y}_i) = \sum_{i=1}^ne_i = 0\]</span></p>
<div class="fragment">
<p>👉 <em>The sum of observations <span class="math inline">\(y_i\)</span> equals the sum of the fitted values <span class="math inline">\(\hat{y}_i\)</span>.</em></p>
<p><span class="math display">\[\scriptstyle  \sum_{i=1}^ny_i = \sum_{i=1}^n\hat{y}_i\]</span></p>
</div>
<div class="fragment">
<p>👉 <em>The LS regression line passes through the centroid of data <span class="math inline">\((\overline{x}, \overline{y})\)</span>.</em></p>
</div>
<div class="fragment">
<p>👉 <em>Inner product of residual and predictor is zero.</em> <span class="math display">\[\scriptstyle \sum_{i=1}^nx_ie_i = 0\]</span></p>
</div>
<div class="fragment">
<p>👉 <em>Inner product of residual and fitted value is zero.</em> <span class="math display">\[\scriptstyle  \sum_{i=1}^n\hat{y}_ie_i = 0\]</span></p>
<aside class="notes"><ul>
<li>Sum of residuals weighted by the corresponding predictor value is zero.</li>
<li>This actually implies that the correlation between x and e is 0.</li>
<li>the residuals are everything that is not related to <span class="math inline">\(x\)</span>, after fitting the regression model.</li>
<li>residuals contain information that is NOT related to <span class="math inline">\(x\)</span> or cannot be explained by <span class="math inline">\(x\)</span>.</li>
<li>Sum of residuals weighted by the corresponding fitted value is zero.</li>
<li>the correlation or covariance between and e is 0 as well.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="estimation-for-sigma2" class="slide level2"><h2>Estimation for <span class="math inline">\(\sigma^2\)</span>
</h2>
<ul>
<li>Think of <span class="math inline">\(\sigma^2\)</span> as <strong>variance around the line</strong> or the <strong>mean squared error</strong>.</li>
<li>The estimate of <span class="math inline">\(\sigma^2\)</span>, denoted as <span class="math inline">\(s^2\)</span> computed from the sample data is <span class="math display">\[s^2 = \frac{SS_{res}}{n-2} = \frac{\sum_{i=1}^n(y_i - \hat{y}_i)^2}{n-2} = MS_{res}\]</span>
</li>
<li>The estimated variance <span class="math inline">\(MS_{res}\)</span>, called <strong>mean squared residual</strong>, is often shown in computer output as <span class="math inline">\(\texttt{MS(Error)}\)</span> or <span class="math inline">\(\texttt{MS(Residual)}\)</span>.</li>
<li>
<span class="math inline">\(E(MS_{res}) = \sigma^2\)</span>, i.e., <span class="math inline">\(s^2\)</span> is an unbiased estimator for <span class="math inline">\(\sigma^2\)</span>. 👍</li>
</ul>
<aside class="notes"><ul>
<li>So we are done estimation for <span class="math inline">\(beta\)</span>. Let’s talk about the estimation of <span class="math inline">\(\sigma^2\)</span>.</li>
<li>The estimate of <span class="math inline">\(\sigma^2\)</span>, denoted as <span class="math inline">\(s^2\)</span> or <span class="math inline">\(s_{\epsilon}^2\)</span>, based on the sample data is residual sum of squares divided by <span class="math inline">\(n-2\)</span>, the degrees of freedom</li>
<li>It can be shown that <span class="math inline">\(E(SS_{res}) = (n-2)\sigma^2\)</span>. That is, <span class="math inline">\(s^2\)</span> is an <em>unbiased</em> estimator for <span class="math inline">\(\sigma^2\)</span>. 👍</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="model-dependent-estimate-of-sigma2" class="slide level2"><h2>Model-dependent estimate of <span class="math inline">\(\sigma^2\)</span>
</h2>
<ul>
<li>
<span class="math inline">\(s\)</span>: the <strong>residual standard error</strong> or <strong>standard error of regression</strong>, is a measure of the <em>lack of fit</em> of the regression model to the data.</li>
<li>If <span class="math inline">\(\hat{y}_i \approx y_i\)</span>, then <span class="math inline">\(s\)</span> will be small, and the model fits the data well.</li>
<li>If <span class="math inline">\(\hat{y}_i\)</span> is far away from <span class="math inline">\(y_i\)</span>, <span class="math inline">\(s\)</span> may be large, indicating the model does not fit the data well.</li>
</ul>

<img data-src="./images/04-slr/unnamed-chunk-16-1.png" style="width:100.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>If the fitted value using the model is close to the true value, <span class="math inline">\(\hat{y}_i \approx y_i\)</span>, then <span class="math inline">\(s\)</span> will be small, and the model fits the data well.</li>
<li>If <span class="math inline">\(\hat{y}_i\)</span> is far away from <span class="math inline">\(y_i\)</span>, <span class="math inline">\(s\)</span> may be large, indicating that the model does not fit the data well.</li>
<li>Let’s see the example shown below. If X and Y have a linear relationship and the relationship is pretty tight, we should see the fitted values on the fitted line are close to the observations, and the <span class="math inline">\(s\)</span> will be small.</li>
<li>But if X and Y have a quadratic relationship, but we fit a linear regression, the fitted values will be distant from the observations, and <span class="math inline">\(s\)</span> may be large.</li>
<li>The case on the right shows the violation of constant variance. In this case, the fitted values are away from the observations too, resulting in large <span class="math inline">\(s\)</span>, and indicating the model does not fit the data well. OK.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="r-lab-standard-error-of-regression" class="slide level2"><h2>
<span class="pink">R Lab</span> Standard Error of Regression</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a>(summ_reg_fit <span class="ot">&lt;-</span> <span class="fu">summary</span>(reg_fit))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb22"><pre class="sourceCode numberSource my_class800 number-lines code-with-copy"><code class="sourceCode"><span id="cb22-1"><a href="#cb22-1"></a></span>
<span id="cb22-2"><a href="#cb22-2"></a>Call:</span>
<span id="cb22-3"><a href="#cb22-3"></a>lm(formula = hwy ~ displ, data = mpg)</span>
<span id="cb22-4"><a href="#cb22-4"></a></span>
<span id="cb22-5"><a href="#cb22-5"></a>Residuals:</span>
<span id="cb22-6"><a href="#cb22-6"></a>   Min     1Q Median     3Q    Max </span>
<span id="cb22-7"><a href="#cb22-7"></a>-7.104 -2.165 -0.224  2.059 15.010 </span>
<span id="cb22-8"><a href="#cb22-8"></a></span>
<span id="cb22-9"><a href="#cb22-9"></a>Coefficients:</span>
<span id="cb22-10"><a href="#cb22-10"></a>            Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb22-11"><a href="#cb22-11"></a>(Intercept)   35.698      0.720    49.5   &lt;2e-16 ***</span>
<span id="cb22-12"><a href="#cb22-12"></a>displ         -3.531      0.195   -18.1   &lt;2e-16 ***</span>
<span id="cb22-13"><a href="#cb22-13"></a>---</span>
<span id="cb22-14"><a href="#cb22-14"></a>Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span id="cb22-15"><a href="#cb22-15"></a></span>
<span id="cb22-16"><a href="#cb22-16"></a>Residual standard error: 3.84 on 232 degrees of freedom</span>
<span id="cb22-17"><a href="#cb22-17"></a>Multiple R-squared:  0.587, Adjusted R-squared:  0.585 </span>
<span id="cb22-18"><a href="#cb22-18"></a>F-statistic:  329 on 1 and 232 DF,  p-value: &lt;2e-16</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<aside class="notes"><ul>
<li>How do we get sigma_hat in R?</li>
<li>Well you could grab residuals and df from lm fit result reg_fit, and use the formula to calculate the sigma_hat. sqrt(sum(reg_fit<span class="math inline">\(residuals^2) / reg_fit\)</span>df.residual)</li>
<li>If you want R to do the calculation for you, you can get the summary of the fitted result reg_fit.</li>
<li>Then the sigma hat is right here.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="r-lab-standard-error-of-regression-1" class="slide level2"><h2>
<span class="pink">R Lab</span> Standard Error of Regression</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a><span class="co"># lots of fitted information saved in summary(reg_fit)!</span></span>
<span id="cb23-2"><a href="#cb23-2"></a><span class="fu">names</span>(summ_reg_fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "call"          "terms"         "residuals"     "coefficients" 
 [5] "aliased"       "sigma"         "df"            "r.squared"    
 [9] "adj.r.squared" "fstatistic"    "cov.unscaled" </code></pre>
</div>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># residual standard error (sigma_hat)</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>summ_reg_fit<span class="sc">$</span>sigma</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.84</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a><span class="co"># from reg_fit</span></span>
<span id="cb27-2"><a href="#cb27-2"></a><span class="fu">sqrt</span>(<span class="fu">sum</span>(reg_fit<span class="sc">$</span>residuals <span class="sc">^</span> <span class="dv">2</span>) <span class="sc">/</span> reg_fit<span class="sc">$</span>df.residual)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.84</code></pre>
</div>
</div>
<aside class="notes"><ul>
<li>Here shows the fitted information saved in summary(reg_fit)</li>
<li>You see sigma is right here. So you just extract that value if you need.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section></section><section><section id="inference" class="title-slide slide level1 center"><h1>Inference</h1>
<h2>
Interval Estimation and Hypothesis Testing
</h2>
<div class="instructions">
<p>The inference methods requires the model assumptions to be satisfied!</p>
</div>
<aside class="notes"><ul>
<li>So far we only have the point estimates of the parameters.</li>
<li>But we don’t just want point estimates, and we can do more inference about the parameters, including interval estimation and hypothesis testing.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="sampling-distribution-of-b_0-and-b_1" class="slide level2"><h2>Sampling Distribution of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>
</h2>
<div class="question">
<p>If <span class="math inline">\(y_i\)</span> ( given <span class="math inline">\(x_i\)</span> ) is normally distributed, do <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> follow normal distribution too?</p>
</div>
<div class="tip">
<p>If <span class="math inline">\(Z_1, \dots, Z_n\)</span> are normal variables and constants <span class="math inline">\(c_1, \dots, c_n \in \mathbf{R}\)</span>, then <span class="math inline">\(c_1Z_1 + \dots + c_nZ_n\)</span> is also a normal variable.</p>
</div>
<div class="fragment">
<ul>
<li>
<span class="math inline">\(b_1 \sim N\left(\beta_1, \frac{\sigma^2}{S_{xx}} \right)\)</span>; <span class="math inline">\(\quad b_0 \sim N\left(\beta_0, \sigma^2\left(\frac{1}{n} + \frac{\overline{x}^2}{S_{xx}} \right) \right)\)</span>
</li>
</ul>
<aside class="notes"><ul>
<li>We skip the proof here due to time limit.</li>
<li>Maybe I will ask you to prove it in your homework or exam.</li>
<li>This looks pretty similar to what we reviewed last week, right?</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
<div class="fragment">
<ul>
<li>
<span class="math inline">\(\small \frac{b_1 - \beta_1}{\sqrt{\sigma^2/S_{xx}}} \sim N\left(0, 1 \right)\)</span>; <span class="math inline">\(\small \quad \frac{b_0 - \beta_0}{\sqrt{\sigma^2 \left(\frac{1}{n} + \frac{\overline{x}^2}{S_{xx}}\right)}} \sim N\left(0, 1 \right)\)</span>
</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>
<span class="math inline">\(\small \frac{b_1 - \beta_1}{\sqrt{s^2/S_{xx}}} \sim t_{n-2}\)</span>; <span class="math inline">\(\small \quad \frac{b_0 - \beta_0}{\sqrt{s^2\left(\frac{1}{n} + \frac{\overline{x}^2}{S_{xx}}\right)}} \sim t_{n-2}\)</span>
</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>
<span class="math inline">\((1-\alpha)100\%\)</span> CI for <span class="math inline">\(\beta_1\)</span> is <span class="math inline">\(\small b_1 \pm t_{\alpha/2, n-2}\sqrt{s^2/S_{xx}}\)</span>
</li>
<li>
<span class="math inline">\((1-\alpha)100\%\)</span> CI for <span class="math inline">\(\beta_0\)</span> is <span class="math inline">\(\small b_0 \pm t_{\alpha/2, n-2}\sqrt{s^2\left(\frac{1}{n} + \frac{\overline{x}^2}{S_{xx}}\right)}\)</span>
</li>
</ul>
</div>
</section><section id="sampling-distribution-of-s2" class="slide level2"><h2>Sampling Distribution of <span class="math inline">\(S^2\)</span>
</h2>
<ul>
<li><span class="math inline">\(\frac{SS_{res}}{\sigma^2} \sim \chi^2_{n-2}\)</span></li>
<li><span class="math inline">\(\frac{SS_{res}}{n-2} = MS_{res} = S^2 \sim \sigma^2 \frac{\chi^2_{n-2}}{n-2}\)</span></li>
</ul>
<aside class="notes"><ul>
<li>We skip the proof here because the proof is not easy as one imagines.</li>
<li>You just need to know this fact, and know how to use it. That’s enough.</li>
<li>We will prove this result after we learn liner algebra and multiple regression.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside><div class="fragment">
<ul>
<li>
<span class="math inline">\((1-\alpha)100\%\)</span> CI for <span class="math inline">\(\sigma^2\)</span> is <span class="math inline">\(\left(\frac{SS_{res}}{\chi^2_{\alpha/2, n-2}}, \frac{SS_{res}}{\chi^2_{1-\alpha/2, n-2}}\right)\)</span>
</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/unnamed-chunk-19-1.png" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</section><section id="r-lab-confidence-interval" class="slide level2"><h2>
<span class="pink">R Lab</span> Confidence Interval</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a><span class="do">## Confidence interval for beta_0 and beta_1</span></span>
<span id="cb29-2"><a href="#cb29-2"></a><span class="fu">confint</span>(reg_fit, <span class="at">level =</span> <span class="fl">0.95</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            2.5 % 97.5 %
(Intercept) 34.28  37.12
displ       -3.91  -3.15</code></pre>
</div>
</div>
<div class="fragment">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1"></a><span class="do">## Confidence interval for sigma^2 (no built-in function)</span></span>
<span id="cb31-2"><a href="#cb31-2"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb31-3"><a href="#cb31-3"></a>SS_res <span class="ot">&lt;-</span> <span class="fu">sum</span>(reg_fit<span class="sc">$</span>residuals <span class="sc">^</span> <span class="dv">2</span>)</span>
<span id="cb31-4"><a href="#cb31-4"></a>low_bd <span class="ot">&lt;-</span> SS_res <span class="sc">/</span> <span class="fu">qchisq</span>(alpha <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> reg_fit<span class="sc">$</span>df, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb31-5"><a href="#cb31-5"></a>upp_bd <span class="ot">&lt;-</span> SS_res <span class="sc">/</span> <span class="fu">qchisq</span>(alpha <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> reg_fit<span class="sc">$</span>df, <span class="at">lower.tail =</span> <span class="cn">TRUE</span>)</span>
<span id="cb31-6"><a href="#cb31-6"></a>low_bd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 12.4</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1"></a>upp_bd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 17.8</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1"></a><span class="co"># MS_res (sigma_hat^2)</span></span>
<span id="cb35-2"><a href="#cb35-2"></a>summ_reg_fit<span class="sc">$</span>sigma <span class="sc">^</span> <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.7</code></pre>
</div>
</div>
<aside class="notes"><ul>
<li>Forget about the proof.</li>
<li>Let’s be practical and see how to get those numbers in R.</li>
<li>There is no built-in function for Confidence interval for sigma^2. You can write your own function to compute it though.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="hypothesis-testing-beta_1" class="slide level2"><h2>Hypothesis Testing: <span class="math inline">\(\beta_1\)</span>
</h2>
<ul>
<li><span style="color:blue"> <span class="math inline">\(H_0: \beta_1 = \beta_1^0 \quad H_1: \beta_1 \ne \beta_1^0\)</span> </span></li>
<li>standard error of <span class="math inline">\(b_1\)</span>: <span class="math inline">\(se(b_1) = \sqrt{\frac{MS_{res}}{S_{xx}}}\)</span>
</li>
<li>Test statistic: <span class="math inline">\(t_{test} = \frac{b_1 - \color{red}{\beta_1^0}}{se(b_1)} \sim t_{n-2}\)</span> under <span class="math inline">\(H_0\)</span>.</li>
<li>Reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_1\)</span> if
<ul>
<li>
<span class="math inline">\(|t_{test}| &gt; t_{\alpha/2, \, n-2}\)</span> (critical value method)</li>
<li>
<span class="math inline">\(\text{p-value} = 2P(t_{n-2} &gt; |t_{test}|) &lt; \alpha\)</span> (p-value method)</li>
</ul>
</li>
</ul>
<aside class="notes"><ul>
<li>in addition to estimation, we may be interested in testing.</li>
<li>To do the testing on <span class="math inline">\(\beta_1\)</span>, the testing procedure is basically the same as the procedure for population mean <span class="math inline">\(\mu\)</span> we reviewed last week.</li>
<li>Usually <span class="math inline">\(\beta_1^0 = 0\)</span>, but we may be interested in other values.</li>
<li>good growth <span class="math inline">\(\beta_1 &gt; 2\)</span>
</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="hypothesis-testing-beta_0" class="slide level2"><h2>Hypothesis Testing: <span class="math inline">\(\beta_0\)</span>
</h2>
<ul>
<li><span style="color:blue"> <span class="math inline">\(H_0: \beta_0 = \beta_0^0 \quad H_1: \beta_0 \ne \beta_0^0\)</span> </span></li>
<li>standard error of <span class="math inline">\(b_0\)</span>: <span class="math inline">\(se(b_0) = \sqrt{MS_{res}\left(1/n + \overline{x}^2/S_{xx}\right)}\)</span>
</li>
<li>Test statistic: <span class="math inline">\(t_{test} = \frac{b_0 - \color{red}{\beta_0^0}}{se(b_0)} \sim t_{n-2}\)</span> under <span class="math inline">\(H_0\)</span>
</li>
<li>Reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_1\)</span> if
<ul>
<li>
<span class="math inline">\(|t_{test}| &gt; t_{\alpha/2, \, n-2}\)</span> (critical value method)</li>
<li>
<span class="math inline">\(\text{p-value} = 2P(t_{n-2} &gt; |t_{test}|) &lt; \alpha\)</span> (p-value method)</li>
</ul>
</li>
</ul>
<aside class="notes"><ul>
<li>Here is the <span class="math inline">\(\beta_0\)</span> version of the testing.</li>
<li>Basically we are more interested in <span class="math inline">\(\beta_1\)</span> because <span class="math inline">\(\beta_1\)</span> sort of measures the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</li>
<li>Again it depends on your research question.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="hypothesis-testing-beta_0-1" class="slide level2"><h2>Hypothesis Testing: <span class="math inline">\(\beta_0\)</span>
</h2>
<ul>
<li><span style="color:blue"> <span class="math inline">\(H_0: \beta_0 = \beta_0^0 \quad H_1: \beta_0 \ne \beta_0^0\)</span> </span></li>
<li>standard error of <span class="math inline">\(b_0\)</span>: <span class="math inline">\(se(b_0) = \sqrt{MS_{res}\left(1/n + \overline{x}^2/S_{xx}\right)}\)</span>
</li>
<li>Test statistic: <span class="math inline">\(t_{test} = \frac{b_0 - \color{red}{\beta_0^0}}{se(b_0)} \sim t_{n-2}\)</span> under <span class="math inline">\(H_0\)</span>
</li>
<li>Reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_1\)</span> if
<ul>
<li>
<span class="math inline">\(|t_{test}| &gt; t_{\alpha/2, \, n-2}\)</span> (critical value method)</li>
<li>
<span class="math inline">\(\text{p-value} = 2P(t_{n-2} &gt; |t_{test}|) &lt; \alpha\)</span> (p-value method)</li>
</ul>
</li>
</ul>
<aside class="notes"><ul>
<li>Here is the <span class="math inline">\(\beta_0\)</span> version of the testing.</li>
<li>Basically we are more interested in <span class="math inline">\(\beta_1\)</span> because <span class="math inline">\(\beta_1\)</span> sort of measures the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</li>
<li>Again it depends on your research question.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="r-lab-testing-on-beta_0-and-beta_1" class="slide level2"><h2>
<span class="pink">R Lab</span> Testing on <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>
</h2>
<div class="cell" data-layout-align="center" data-output.lines="[3,4,5,6,7,8,9,10,11,12,13,14]">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1"></a>summ_reg_fit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb38"><pre class="sourceCode numberSource my_class600 number-lines code-with-copy"><code class="sourceCode"><span id="cb38-1"><a href="#cb38-1"></a>...</span>
<span id="cb38-2"><a href="#cb38-2"></a>lm(formula = hwy ~ displ, data = mpg)</span>
<span id="cb38-3"><a href="#cb38-3"></a></span>
<span id="cb38-4"><a href="#cb38-4"></a>Residuals:</span>
<span id="cb38-5"><a href="#cb38-5"></a>   Min     1Q Median     3Q    Max </span>
<span id="cb38-6"><a href="#cb38-6"></a>-7.104 -2.165 -0.224  2.059 15.010 </span>
<span id="cb38-7"><a href="#cb38-7"></a></span>
<span id="cb38-8"><a href="#cb38-8"></a>Coefficients:</span>
<span id="cb38-9"><a href="#cb38-9"></a>            Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb38-10"><a href="#cb38-10"></a>(Intercept)   35.698      0.720    49.5   &lt;2e-16 ***</span>
<span id="cb38-11"><a href="#cb38-11"></a>displ         -3.531      0.195   -18.1   &lt;2e-16 ***</span>
<span id="cb38-12"><a href="#cb38-12"></a>---</span>
<span id="cb38-13"><a href="#cb38-13"></a>Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span id="cb38-14"><a href="#cb38-14"></a>...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1"></a>summ_reg_fit<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)    35.70      0.720    49.6 2.12e-125
displ          -3.53      0.195   -18.2  2.04e-46</code></pre>
</div>
</div>
<ul>
<li>Testing <span class="math inline">\(H_0: \beta_0 = 0\)</span> and <span class="math inline">\(H_0: \beta_1 = 0\)</span>
</li>
</ul></section><section id="interpretation-of-testing-results" class="slide level2"><h2>Interpretation of Testing Results</h2>
<ul>
<li><span style="color:blue"> <span class="math inline">\(H_0: \beta_1 = 0 \quad H_1: \beta_1 \ne 0\)</span> </span></li>
<li>
<em>Failing to reject <span class="math inline">\(H_0: \beta_1 = 0\)</span></em> implies there is <strong>no linear relationship</strong> between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>.</li>
</ul>
<aside class="notes"><ul>
<li>So back to the testing on <span class="math inline">\(\beta_1\)</span>.</li>
<li>If we do not reject <span class="math inline">\(H_0\)</span>, it implies there is <strong>no linear relationship</strong> between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>. Right? Because <span class="math inline">\(\beta_1\)</span>, the slope of the regression line is pretty much 0.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside><div class="fragment">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/unnamed-chunk-25-1.png" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
</div>
<div class="fragment">
<div class="question">
<p>If we reject <span class="math inline">\(H_0: \beta_1 = 0\)</span>, does it mean <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are linearly related?</p>
</div>
<aside class="notes"><ul>
<li>But it actually has two cases. One <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> may have no relationship at all, or they don’t have linear relationship but have another kind of relationship, like quadratic.</li>
<li>So we have to be careful when we interpret the testing result. OK.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside><aside class="notes"><p>We have to be more careful and precise on what we are claiming.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="test-of-significance-of-regression" class="slide level2"><h2>Test of Significance of Regression</h2>
<ul>
<li>
<em>Rejecting <span class="math inline">\(H_0: \beta_1 = 0\)</span></em> could mean
<ul>
<li>the straight-line model is adequate</li>
<li>better results could be obtained with a more complicated model</li>
</ul>
</li>
</ul>

<img data-src="./images/04-slr/unnamed-chunk-26-1.png" style="width:65.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>
<em>Rejecting <span class="math inline">\(H_0: \beta_1 = 0\)</span></em> could mean
<ul>
<li>the straight-line model is adequate</li>
<li>better results could be obtained with a more complicated model even though there is a linear effect of <span class="math inline">\(x\)</span>
</li>
</ul>
</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section></section><section><section id="analysis-of-variance-anova-approach" class="title-slide slide level1 center"><h1>Analysis of Variance (ANOVA) Approach</h1>
<aside class="notes"><ul>
<li>Let’s talk about ANOVA, the idea of partitioning the total variability.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="x---y-relationship-explains-some-deviation" class="slide level2"><h2>
<span class="math inline">\(X\)</span> - <span class="math inline">\(Y\)</span> Relationship Explains Some Deviation</h2>
<div class="question">
<p>Suppose we only have data <span class="math inline">\(Y\)</span> and have no information about <span class="math inline">\(X\)</span> or no information about the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. How do we predict a value of <span class="math inline">\(Y\)</span>?</p>
</div>
<aside class="notes"><ul>
<li>For example, suppose we only have MPG information for the sample of cars and have no info about displacement and their relationship. How do we predict a car’s MPG?</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside><div class="fragment">
<ul>
<li><p>Our best guess would be <span class="math inline">\(\overline{y}\)</span> if the data have no pattern, i.e., <span class="math inline">\(\hat{y}_i = \overline{y}\)</span>.</p></li>
<li><p>As we were treating <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> as uncorrelated.</p></li>
<li><p>The (total) deviation from the mean is <span class="math inline">\((y_i - \overline{y})\)</span>.</p></li>
</ul>
<aside class="notes"><ul>
<li>When we have no information about the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, to predict a value of <span class="math inline">\(y\)</span> using the same value given any value of <span class="math inline">\(x\)</span>.</li>
<li>When <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are uncorrelated, the regression model is not helping predict <span class="math inline">\(Y\)</span> because <span class="math inline">\(X\)</span> provides no information about <span class="math inline">\(Y\)</span>.</li>
<li>It means <span class="math inline">\(b_1 = 0\)</span> and <span class="math inline">\(\hat{y}_i = \bar{y}\)</span> for all values of <span class="math inline">\(X\)</span>.</li>
<li>The result is the same as the one when we only have data of <span class="math inline">\(Y\)</span>.</li>
<li>This prediction deviation <span class="math inline">\((y_i - \overline{y})\)</span> is generally the biggest deviation we can have when we have no information about how y varies or how y is affected by others.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
<div class="fragment">
<ul>
<li><p>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are linearly related, fitting a linear regression helps us predict the value of <span class="math inline">\(Y\)</span> when the value of <span class="math inline">\(X\)</span> is provided.</p></li>
<li><p><span class="math inline">\(\hat{y}_i = b_0 + b_1x_i\)</span> is closer to <span class="math inline">\(y_i\)</span> than <span class="math inline">\(\overline{y}\)</span>.</p></li>
<li><p>The regression model explains some deviation of <span class="math inline">\(y\)</span>.</p></li>
</ul>
</div>
</section><section id="partition-of-deviation" class="slide level2"><h2>Partition of Deviation</h2>
<ul>
<li><p><strong>Total deviation = Deviation explained by regression + Unexplained deviation</strong></p></li>
<li><p><span class="math inline">\((y_i - \overline{y}) = (\hat{y}_i - \overline{y}) + (y_i - \hat{y}_i)\)</span></p></li>
<li><p><span class="math inline">\((19 - 9) = (13 - 9) + (19 - 13)\)</span></p></li>
</ul>

<img data-src="./images/04-slr/partition.png" style="width:100.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>So, we can actually Partition the total deviation into two parts.</li>
<li>Partition of deviation: <strong>Total deviation = Explained deviation by regression + Unexplained deviation</strong>
</li>
<li><span class="math inline">\((y_i - \overline{y}) = (\hat{y}_i - \overline{y}) + (y_i - \hat{y}_i)\)</span></li>
<li>Here gives you a graphical example.</li>
<li>Take <span class="math inline">\(y_1\)</span> for example. The total deviation is <span class="math inline">\(y_1 - \bar{y}\)</span>, the red vertical line.</li>
<li>Now suppose X and Y are linear related, and we fit a linear regression model, then the fitted value is <span class="math inline">\(\hat{y}_1\)</span>.</li>
<li>Note that <span class="math inline">\(\hat{y}_1\)</span> is closer to <span class="math inline">\(y_1\)</span>, and the regression does provide some prediction power, although the two are not exactly the same.</li>
<li>The deviation <span class="math inline">\((\hat{y}_1 - \overline{y})\)</span> is the amount of deviation reduced or explained by the regressor <span class="math inline">\(X\)</span>.</li>
<li>The difference between the fitted value and the observation is the deviation that can not explained or captured by the predictor <span class="math inline">\(X\)</span>.</li>
<li>Even we already make use of the information <span class="math inline">\(X\)</span> provide, some deviation is still there and remained unexplained.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="sum-of-squares-ss" class="slide level2"><h2>Sum of Squares (SS)</h2>
<ul>
<li><span class="math inline">\(\sum_{i=1}^n(y_i - \overline{y})^2 = \sum_{i=1}^n(\hat{y}_i - \overline{y})^2 + \sum_{i=1}^n(y_i - \hat{y}_i)^2\)</span></li>
<li><strong>Total SS <span class="math inline">\((SS_T)\)</span> = Regression SS <span class="math inline">\((SS_R)\)</span> + Residual SS <span class="math inline">\((SS_{res})\)</span></strong></li>
<li><span class="math inline">\(df_T = df_R + df_{res}\)</span></li>
<li><span class="math inline">\(\color{blue}{(n-1) = 1 +(n-2)}\)</span></li>
</ul>
<div class="fragment">
<ul>
<li>
<span style="color:blue"> <span class="math inline">\(df_T = n - 1\)</span></span>: lose 1 df with constraint <span class="math inline">\(\sum_{i=1}^n(y_i - \overline{y}) = 0\)</span>
</li>
<li>
<span style="color:blue"> <span class="math inline">\(df_R = 1\)</span></span>: all <span class="math inline">\(\hat{y}_i\)</span> are on the regression line with 2 dfs (intercept and slope), but with constraint <span class="math inline">\(\sum_{i=1}^n(\hat{y}_i - \overline{y}) = 0\)</span>
</li>
<li>
<span style="color:blue"> <span class="math inline">\(df_{res} = n - 2\)</span></span>: lose 2 dfs because <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are estimated by <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, which are linear combo of <span class="math inline">\(y_i\)</span>
</li>
</ul>
<aside class="notes"><ul>
<li>Total variability = variability explained by regression + unexplained variability</li>
<li><span class="math inline">\(\sum_{i=1}^n(y_i - \overline{y})^2 = \sum_{i=1}^n(\hat{y}_i - \overline{y})^2 + \sum_{i=1}^n(y_i - \hat{y}_i)^2 + 2\sum_{i=1}^n(\hat{y}_i - \overline{y})(y_i - \hat{y}_i)\)</span></li>
<li>
</li><li>
<span style="color:blue"> <span class="math inline">\(df_T = n - 1\)</span></span>: lose 1 df with constraint <span class="math inline">\(\sum_{i=1}^n(y_i - \overline{y}) = 0\)</span>
</li>
<li>
<span style="color:blue"> <span class="math inline">\(df_R = 1\)</span></span>: all <span class="math inline">\(\hat{y}_i\)</span> are on the regression line with 2 dfs (intercept and slope), but with constraint <span class="math inline">\(\sum_{i=1}^n(\hat{y}_i - \overline{y}) = 0\)</span>
</li>
<li>
<span style="color:blue"> <span class="math inline">\(df_{res} = n - 2\)</span></span>: lose 2 dfs because <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are estimated by <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, which are linear combo of <span class="math inline">\(y_i\)</span>
</li>
<li>degrees of freedom is the equivalent number of values in the calculation of a statistic that are free to vary.</li>
<li>
<span class="math inline">\(SS_R = b_1S_{xy}\)</span> or <span class="math inline">\(SS_{res} = SS_T - b_1S_{xy}\)</span>.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="anova-for-testing-significance-of-regression" class="slide level2"><h2>ANOVA for Testing Significance of Regression</h2>

<img data-src="./images/04-slr/anova_table.png" style="width:100.0%" class="r-stretch quarto-figure-center"><ul>
<li>A larger value of <span class="math inline">\(F_{test}\)</span> indicates that regression is significant.</li>
<li>Reject <span class="math inline">\(H_0\)</span> if
<ul>
<li><span class="math inline">\(F_{test} &gt; F_{\alpha, 1, n-2}\)</span></li>
<li>
<span class="math inline">\(\text{p-value} = P(F_{1, n-2} &gt; F_{test}) &lt; \alpha\)</span>.</li>
</ul>
</li>
<li>The ANOVA is designed to test <span class="math inline">\(H_0\)</span> that <strong>all</strong> predictors have no value in predicting <span class="math inline">\(y\)</span>.</li>
<li>In SLR, the <span class="math inline">\(F\)</span>-test gives the same result as a two-sided <span class="math inline">\(t\)</span>-test of <span class="math inline">\(H_0: \beta_1=0\)</span>.</li>
</ul>
<aside class="notes"><ul>
<li>ANOVA is used for testing significance of regression.</li>
<li>It is testing if any predictors or regressors have explanatory power for predicting y.</li>
<li>In other words, it is testing if the whole regression model is useful or not.</li>
<li>Here is the ANOVA table.</li>
<li><span class="math inline">\(H_0: \beta_1 = 0\)</span></li>
<li>A larger value of <span class="math inline">\(F_{test}\)</span> indicates that regression is significant.</li>
<li>Reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_1\)</span> if <span class="math inline">\(F_{test} &gt; F_{\alpha, 1, n-2}\)</span> or <span class="math inline">\(\text{p-value} = P(F_{1, n-2} &gt; F_{test}) &lt; \alpha\)</span>.</li>
<li>The ANOVA is designed to test <span class="math inline">\(H_0\)</span> that <strong>all</strong> predictors have no value in predicting <span class="math inline">\(y\)</span>.</li>
<li>In SLR, there is only one predictor, and hence the <span class="math inline">\(F\)</span>-test of ANOVA gives the same result as a two-sided <span class="math inline">\(t\)</span>-test of <span class="math inline">\(H_0: \beta_1=0\)</span>.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside><div class="fragment">
<div class="question">
<p>What is the <span class="math inline">\(H_0\)</span> of ANOVA <span class="math inline">\(F\)</span>-test if there are <span class="math inline">\(k \ge 2\)</span> predictors?</p>
</div>
<aside class="notes"><ul>
<li>If we have <span class="math inline">\(k \ge 2\)</span> predictors, the <span class="math inline">\(F\)</span>-test is testing <span class="math inline">\(H_0: \beta_1=\beta_2=\cdots=\beta_k=0\)</span>.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="r-lab-anova-table" class="slide level2"><h2>
<span class="pink">R Lab</span> ANOVA Table</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1"></a><span class="fu">anova</span>(reg_fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: hwy
           Df Sum Sq Mean Sq F value Pr(&gt;F)    
displ       1   4848    4848     329 &lt;2e-16 ***
Residuals 232   3414      15                   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<div class="fragment">
<ul>
<li>For <span class="math inline">\(H_0: \beta_1 = 0\)</span> in SLR, <span class="math inline">\(t_{test}^2 = F_{test}\)</span>.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1"></a>summ_reg_fit<span class="sc">$</span>coefficients </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)    35.70      0.720    49.6 2.12e-125
displ          -3.53      0.195   -18.2  2.04e-46</code></pre>
</div>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1"></a>summ_reg_fit<span class="sc">$</span>coefficients[<span class="dv">2</span>, <span class="dv">3</span>] <span class="sc">^</span> <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 329</code></pre>
</div>
</div>
<aside class="notes"><ul>
<li>For <span class="math inline">\(H_0: \beta_1 = 0\)</span>, <span class="math inline">\(t_{test}^2 = \left(\frac{b_1}{\sqrt{MS_{res}/S_{xx}}}\right)^2 = \frac{b_1^2S_{xx}}{MS_{res}} = \frac{b_1S_{xy}}{MS_{res}} = \frac{MS_R}{MS_{res}} = F_{test}\)</span>
</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="coefficient-of-determination" class="slide level2"><h2>Coefficient of Determination</h2>
<ul>
<li><p>The <strong>coefficient of determination</strong> <span class="math inline">\((R^2)\)</span> is the proportion of the variation in <span class="math inline">\(y\)</span> that is explained by the regression model: <span class="math display">\[R^2 = \frac{SS_R}{SS_T} =\frac{SS_T - SS_{res}}{SS_T} = 1 - \frac{SS_{res}}{SS_T}\]</span></p></li>
<li><p><span class="math inline">\(R^2\)</span> as the proportionate reduction of total variation associated with the use of <span class="math inline">\(X\)</span>.</p></li>
<li><p><strong>(a)</strong> <span class="math inline">\(\hat{y}_i = y_i\)</span> and <span class="math inline">\(\small SS_{res} = \sum_{i=1}^n(y_i - \hat{y}_i)^2 = 0\)</span>. <strong>(b)</strong> <span class="math inline">\(\hat{y}_i = \overline{y}\)</span> and <span class="math inline">\(\small SS_R = \sum_{i=1}^n(\hat{y}_i - \overline{y})^2 = 0\)</span>.</p></li>
</ul>

<img data-src="./images/04-slr/r_square.png" style="width:100.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>
<strong>coefficient of determination</strong> can be used to measure the quality of our regression or the explanatory power of regressors.</li>
<li>Here (a) and (b) are two extreme cases.</li>
<li>In (a), the fitted value = the true observation. So the regression model explains all the variation in <span class="math inline">\(Y\)</span>, and hence <span class="math inline">\(R^2 = 1\)</span>.</li>
<li>In (b), the fitted value = mean of y as if we don’t have information about <span class="math inline">\(x\)</span> or <span class="math inline">\(x\)</span> is totally useless in predicting <span class="math inline">\(Y\)</span>. In this case, the regression model explains no the variation in <span class="math inline">\(Y\)</span>, and all variation remain unexplained. So <span class="math inline">\(R^2 = 0\)</span>.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="r-lab-r2" class="slide level2"><h2>
<span class="pink">R Lab</span> <span class="math inline">\(R^2\)</span>
</h2>
<div class="cell" data-layout-align="center" data-output.lines="[10,11,12,13,14,15,16,17,18]">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1"></a>summ_reg_fit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb48"><pre class="sourceCode numberSource my_class500 number-lines code-with-copy"><code class="sourceCode"><span id="cb48-1"><a href="#cb48-1"></a>...</span>
<span id="cb48-2"><a href="#cb48-2"></a>            Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb48-3"><a href="#cb48-3"></a>(Intercept)   35.698      0.720    49.5   &lt;2e-16 ***</span>
<span id="cb48-4"><a href="#cb48-4"></a>displ         -3.531      0.195   -18.1   &lt;2e-16 ***</span>
<span id="cb48-5"><a href="#cb48-5"></a>---</span>
<span id="cb48-6"><a href="#cb48-6"></a>Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span id="cb48-7"><a href="#cb48-7"></a></span>
<span id="cb48-8"><a href="#cb48-8"></a>Residual standard error: 3.84 on 232 degrees of freedom</span>
<span id="cb48-9"><a href="#cb48-9"></a>Multiple R-squared:  0.587, Adjusted R-squared:  0.585 </span>
<span id="cb48-10"><a href="#cb48-10"></a>F-statistic:  329 on 1 and 232 DF,  p-value: &lt;2e-16</span>
<span id="cb48-11"><a href="#cb48-11"></a>...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1"></a>summ_reg_fit<span class="sc">$</span>r.squared</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.587</code></pre>
</div>
</div>
</section></section><section><section id="prediction" class="title-slide slide level1 center"><h1>Prediction</h1>

</section><section id="predicting-the-mean-response-sampling-distribution" class="slide level2"><h2>Predicting the Mean Response: Sampling Distribution</h2>
<ul>
<li>
<p>With predictor value <span class="math inline">\(x = x_0\)</span>, we want to estimate the mean response <span class="math display">\[E(y\mid x_0) = \mu_{y|x_0} = \beta_0 + \beta_1 x_0\]</span>.</p>
<ul>
<li><span style="color:blue"> The <strong>mean</strong> highway MPG <span class="math inline">\(E(y \mid x_0)\)</span> when displacement is <span class="math inline">\(x = x_0 = 5.5\)</span>. </span></li>
</ul>
</li>
<li><p>If <span class="math inline">\(x_0\)</span> is <em>within the range of <span class="math inline">\(x\)</span></em>, an <em>unbiased</em> point estimate of <span class="math inline">\(E(y\mid x_0)\)</span> is <span class="math display">\[\widehat{E(y\mid x_0)} = \hat{\mu}_{y | x_0} = b_0 + b_1 x_0\]</span></p></li>
<li><p>The sampling distribution of <span class="math inline">\(\hat{\mu}_{y | x_0}\)</span> is <span class="math display">\[N\left( \mu_{y | x_0} = \beta_0 + \beta_1 x_0, \sigma^2\left(\frac{1}{n} + \frac{(x_0 - \overline{x})^2}{S_{xx}} \right) \right)\]</span></p></li>
</ul>
<aside class="notes"><ul>
<li>Remember there are two types of prediction, predicting the mean response <span class="math inline">\(E(y\mid x_0)\)</span> and predicting an observation value given a value of <span class="math inline">\(x\)</span>.</li>
<li>Here, we are doing real prediction, because we are not predicting the observation given the <span class="math inline">\(x\)</span> value in the data set, but we use our data set to do prediction when <span class="math inline">\(x\)</span> is a new value that is not in the data set.</li>
<li>So <span class="math inline">\(x_0\)</span> is any new value that is not shown in the data set.</li>
<li>We are interested in predicting a new mean response or new observation given the new value of <span class="math inline">\(X\)</span>. OK.</li>
<li>For a given predictor value <span class="math inline">\(x = x_0\)</span>, we want to estimate the mean response <span class="math inline">\(E(y\mid x_0) = \mu_{y|x_0}.\)</span>
<ul>
<li><span style="color:blue"> The <strong>mean</strong> highway MPG <span class="math inline">\(E(y \mid x_0)\)</span> when displacement is <span class="math inline">\(x = x_0 = 5.5\)</span>. </span></li>
</ul>
</li>
<li>If <span class="math inline">\(x_0\)</span> is within the range of the sample data on <span class="math inline">\(x\)</span>, an unbiased point estimator for <span class="math inline">\(E(y\mid x_0)\)</span> is <span class="math display">\[\widehat{E(y\mid x_0)} = \hat{\mu}_{y | x_0} = b_0 + b_1 x_0\]</span>
</li>
<li>The sampling distribution of <span class="math inline">\(\hat{\mu}_{y | x_0}\)</span> is <span class="math display">\[N\left( \mu_{y | x_0} = \beta_0 + \beta_1 x_0, \sigma^2\left(\frac{1}{n} + \frac{(x_0 - \overline{x})^2}{S_{xx}} \right) \right)\]</span>
</li>
<li>
<span class="math inline">\(\widehat{E(y\mid x_0)} = \hat{\mu}_{y | x_0} = b_0 + b_1 x_0\)</span>; <span class="math inline">\(\quad E(y\mid x_0) = \mu_{y | x_0} = \beta_0 + \beta_1 x_0\)</span>
</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="predicting-the-mean-response-confidence-interval" class="slide level2"><h2>Predicting the Mean Response: Confidence Interval</h2>
<p><span class="math inline">\((\hat{\mu}_{y | x_0} = b_0 + b_1 x_0) \sim N\left( \mu_{y | x_0} = \beta_0 + \beta_1 x_0, \sigma^2\left(\frac{1}{n} + \frac{(x_0 - \overline{x})^2}{S_{xx}} \right) \right)\)</span></p>
<p><span class="math display">\[\frac{(b_0 + b_1 x_0) - (\beta_0 + \beta_1 x_0)}{\sigma\sqrt{\frac{1}{n} + \frac{(x_0 - \overline{x})^2}{S_{xx}}}} \sim N(0, 1)\]</span></p>
<div class="fragment">
<p><span class="math display">\[\frac{(b_0 + b_1 x_0) - (\beta_0 + \beta_1 x_0)}{s\sqrt{\frac{1}{n} + \frac{(x_0 - \overline{x})^2}{S_{xx}}}} \sim t_{n-2}\]</span></p>
</div>
<div class="fragment">
<p>The <span class="math inline">\((1-\alpha)100\%\)</span> CI for <span class="math inline">\(E(y\mid x_0)\)</span> is <span class="math inline">\(\boxed{\hat{\mu}_{y | x_0} \pm t_{\alpha/2, n-2} s\sqrt{\frac{1}{n} + \frac{(x_0 - \overline{x})^2}{S_{xx}}}}\)</span>.</p>
</div>
<div class="fragment">
<div class="question">
<p>Does the length of the CI for <span class="math inline">\(E(y\mid x_0)\)</span> stay the same at any location of <span class="math inline">\(x_0\)</span>?</p>
</div>
<aside class="notes"><ul>
<li>The length of the CI depends on <strong>the location of the point of interest</strong>.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="predicting-new-observations-sampling-distribution" class="slide level2"><h2>Predicting New Observations: Sampling Distribution</h2>
<ul>
<li>Predict the value of a <em>new observation <span class="math inline">\(y_0\)</span></em> with <span class="math inline">\(x = x_0\)</span>.
<ul>
<li><span style="color:blue"> The <strong>highway MPG of a car</strong> <span class="math inline">\(y_0(x_0)\)</span> when its displacement is <span class="math inline">\(x = x_0 = 5.5\)</span>. </span></li>
</ul>
</li>
<li>An <em>unbiased</em> point estimate of <span class="math inline">\(y_0(x_0)\)</span> is <span class="math display">\[\hat{y}_0(x_0) = b_0 + b_1 x_0\]</span>
</li>
</ul>
<div class="fragment">
<div class="question">
<p>What is the sampling distribution of <span class="math inline">\(\hat{y}_0\)</span>?</p>
</div>
</div>
<div class="fragment">
<ul>
<li><span class="math inline">\(\hat{y}_0 = b_0 + b_1 x_0 \sim N\left(\beta_0 + \beta_1 x_0, \sigma^2\left(\frac{1}{n} + \frac{(x_0 - \overline{x})^2}{S_{xx}} \right) \right)\)</span></li>
</ul>
</div>
<div class="fragment">
<div class="question">
<p>What is the distribution of <span class="math inline">\(y_0 = \beta_0 + \beta_1x_0 + \epsilon\)</span>?</p>
</div>
<aside class="notes"><ul>
<li>
<span class="math inline">\(y_0(x_0)\)</span> itself is a r.v.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
<div class="fragment">
<ul>
<li><span class="math inline">\(y_0 \sim N\left(\beta_0 + \beta_1 x_0, \sigma^2 \right)\)</span></li>
</ul>
</div>
<div class="fragment">
<div class="question">
<p>What is the distribution of <span class="math inline">\(y_0 - \hat{y}_0\)</span>?</p>
</div>
<aside class="notes"><ul>
<li>Predict the value of a new observation <span class="math inline">\(y_0\)</span> corresponding to a specified value of predictor <span class="math inline">\(x = x_0\)</span>.
<ul>
<li><span style="color:blue"> The <strong>highway MPG of a car</strong> <span class="math inline">\(y_0(x_0)\)</span> when its displacement is <span class="math inline">\(x = x_0 = 5.5\)</span>. </span></li>
</ul>
</li>
<li>An unbiased point estimator for <span class="math inline">\(y_0(x_0)\)</span> is <span class="math display">\[\hat{y}_0(x_0) = b_0 + b_1 x_0\]</span>
</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="predicting-new-observations-prediction-interval" class="slide level2"><h2>Predicting New Observations: Prediction Interval</h2>
<ul>
<li>
<span class="math inline">\(y_0 - \hat{y}_0 \sim N\left(0, \sigma^2\left(1 + \frac{1}{n} + \frac{(x_0 - \overline{x})^2}{S_{xx}} \right) \right)\)</span> <!-- - $\hat{y}_0(x_0) = b_0 + b_1 x_0$ --> <!-- - $y_0 = \beta_0 + \beta_1x_0 + \epsilon$ -->
</li>
</ul>
<div class="fragment">
<p><span class="math display">\[\frac{(y_0 - \hat{y}_0) - \color{red}{0}}{\sigma\sqrt{1 + \frac{1}{n} + \frac{(x_0 - \overline{x})^2}{S_{xx}}}} \sim N(0, 1)\]</span></p>
</div>
<div class="fragment">
<p><span class="math display">\[\frac{y_0 - \hat{y}_0}{s\sqrt{1 + \frac{1}{n} + \frac{(x_0 - \overline{x})^2}{S_{xx}}}} \sim t_{n-2}\]</span></p>
</div>
<div class="fragment">
<p>The <span class="math inline">\((1-\alpha)100\%\)</span> <strong>prediction interval</strong> (PI) for <span class="math inline">\(y_0(x_0)\)</span> is <span class="math inline">\(\small \boxed{\hat{y_0} \pm t_{\alpha/2, n-2} s\sqrt{1+ \frac{1}{n} + \frac{(x_0 - \overline{x})^2}{S_{xx}}}}\)</span></p>
</div>
<div class="fragment">
<div class="question">
<p>What is the difference between CI for <span class="math inline">\(E(y\mid x_0)\)</span> and PI for <span class="math inline">\(y_0(x_0)\)</span>?</p>
</div>
</div>
<div class="fragment">
<ul>
<li>
<em>The PI is wider as it includes the uncertainty about <span class="math inline">\(b_0\)</span>, <span class="math inline">\(b_1\)</span> as well as <span class="math inline">\(y_0\)</span> due to error <span class="math inline">\(\epsilon\)</span></em>.</li>
</ul>
<aside class="notes"><ul>
<li>The PI at <span class="math inline">\(x_0\)</span> is wider than the CI at <span class="math inline">\(x_0\)</span> because the PI depends on both the uncertainty about the fitted model <span class="math inline">\((b_0\)</span> and <span class="math inline">\(b_1)\)</span> and the error <span class="math inline">\(\epsilon\)</span> associated with the future observation <span class="math inline">\(y_0\)</span>.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section><section id="r-lab-prediction" class="slide level2"><h2>
<span class="pink">R Lab</span> Prediction</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1"></a><span class="do">## CI for the mean response</span></span>
<span id="cb51-2"><a href="#cb51-2"></a><span class="fu">predict</span>(reg_fit, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">displ =</span> <span class="fl">5.5</span>), <span class="at">interval =</span> <span class="st">"confidence"</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   fit  lwr  upr
1 16.3 15.4 17.2</code></pre>
</div>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1"></a><span class="do">## PI for the new observation</span></span>
<span id="cb53-2"><a href="#cb53-2"></a><span class="fu">predict</span>(reg_fit, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">displ =</span> <span class="fl">5.5</span>), <span class="at">interval =</span> <span class="st">"predict"</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   fit  lwr  upr
1 16.3 8.67 23.9</code></pre>
</div>
</div>

<img data-src="./images/04-slr/unnamed-chunk-35-1.png" style="width:43.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>If I can only use one point or value to predict <span class="math inline">\(y_0\)</span>, the best guess is the predicted value on the regression line.</li>
<li>After all, values around the lines would more likely to be drawn based on our model.</li>
<li>Here you can understand why uncertainty quantification is important.</li>
<li>Yes, we can predict an new observation value, but the prediction quality is gonna be bad because we are predict a random variable, not a constant, and <span class="math inline">\(y_0\)</span> can vary a lot around the regression line.</li>
<li>And prediction interval gives us an idea of how good or how bad our prediction is.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="section-3" class="slide level2"><h2></h2>

<img data-src="./images/04-slr/unnamed-chunk-36-1.png" style="width:85.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>CI is the shortest when <span class="math inline">\(x = \bar{x}\)</span>. (Also PI)</li>
<li>PI length looks the same along with <span class="math inline">\(x\)</span> because the <span class="math inline">\(\sigma^2\)</span> dominates the uncertainty, comparing to the uncertainty about <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section></section><section><section id="considerations-in-the-usage-of-regression" class="title-slide slide level1 center"><h1>Considerations in the Usage of Regression</h1>
<aside class="notes"><ul>
<li>Let’s finally talk about some considerations or potential issues when people are doing regression.</li>
<li>So keep these in mind and try to avoid these mistakes when you apply regression methods.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="considerations-in-regression-extrapolation" class="slide level2"><h2>Considerations in Regression: Extrapolation</h2>
<ul>
<li>Regression models are intended as <strong>interpolation</strong> equations over <em>the range of the regressors</em> used to fit the model.</li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/unnamed-chunk-37-1.png" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/unnamed-chunk-38-1.png" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
<aside class="notes"><ul>
<li>First, Regression models are intended as <strong>interpolation</strong> equations over the range of the regressors used to fit the model.</li>
<li>Regression does a really bad job for extrapolation.</li>
<li>Look at this figure for example.</li>
<li>Suppose the data we collected have the range of X like this.</li>
<li>Based on the data, we train our model, and estimate the parameters for prediction and inference.</li>
<li>Our prediction and inference will be more plausible or convicing when the new <span class="math inline">\(x\)</span> is within the range of <span class="math inline">\(X\)</span>.</li>
<li>Again, the only information we have is our data.</li>
<li>When we do extrapolation, it’s like doing a prediction or inference without any reliable information at hand.</li>
<li>Our conclusion may be totally wrong. Based on the collected data, we thought x and y are linear related.</li>
<li>But the true x-y relationship may not be linear at all, and because our data only cover a small range of <span class="math inline">\(X\)</span>, we don’t know what really happens outside the range of data.</li>
<li>We cannot say much about the predictive mean response or observation outside the range of <span class="math inline">\(X\)</span>, and we cannot conclude the relationship between x and y outside the range as well.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="considerations-in-the-use-of-regression-outliers" class="slide level2"><h2>Considerations in the Use of Regression: Outliers</h2>
<ul>
<li>
<strong>Outlier</strong>: An observation that is considerably different from the rest of the data (unusual in <span class="math inline">\(y\)</span> direction)</li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/unnamed-chunk-39-1.png" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<ul>
<li><p>The estimate of the intercept may be incorrect.</p></li>
<li><p>The residual mean square may be inflated.</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1"></a><span class="fu">summary</span>(lm_outlier)<span class="sc">$</span>sigma <span class="sc">^</span> <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1421</code></pre>
</div>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1"></a><span class="fu">summary</span>(lm_no_outlier)<span class="sc">$</span>sigma <span class="sc">^</span> <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 101</code></pre>
</div>
</div>
</div>
</div>
<aside class="notes"><ul>
<li>The second consideration is outlier.</li>
<li>it might be just measurement error.</li>
<li>If it is not an typo, we have to look into this point with great care, and see why this happened and see if we need to do some correction to it.</li>
<li>We will talk about outliers in detail later in this course.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="considerations-in-regression-influential-points" class="slide level2"><h2>Considerations in Regression: Influential Points</h2>
<ul>
<li>
<strong>Influential point</strong>: A point that strongly affects the slope of the line. (unusual in <span class="math inline">\(x\)</span> direction)</li>
</ul>

<img data-src="./images/04-slr/unnamed-chunk-41-1.png" style="width:85.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>Our inference and prediction may be totally distorted just because of one single influential point. So again, we have to very careful about it.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="considerations-in-regression-causal-relationship" class="slide level2"><h2>Considerations in Regression: Causal Relationship?</h2>
<!-- - Correlation is NOT Causation! -->
<!-- - Remember this when interpreting model coefficients! -->
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/icecream.jpeg" style="width:56.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/unnamed-chunk-43-1.png" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/drowning.jpeg" style="width:56.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/unnamed-chunk-45-1.png" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
<aside class="notes"><ul>
<li>Regression is just a model. It does not tell you X-Y’s relationship is correlation relationship or causal relationship.</li>
<li>It is the person who uses the model tell the relationship.</li>
<li>So we have to be careful when interpreting regression result.</li>
<li>They are correlated, not one causes the other.</li>
<li>Actually, there is another factor that causes the sales and # of drownings to go up and down together.</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="considerations-in-regression-unknown-predictor" class="slide level2"><h2>Considerations in Regression: Unknown Predictor</h2>
<ul>
<li>Maximum daily load <span class="math inline">\((Y)\)</span> on an electric power generation system and the maximum daily temperature <span class="math inline">\((X)\)</span>.</li>
<li>To predict tomorrow maximum daily load, we must first know tomorrow maximum temperature.</li>
<li>The prediction of maximum load is <strong>conditional</strong> on the temperature forecast.</li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/electricity.jpeg" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="./images/04-slr/electricity_snow.jpeg" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section></section><section><section id="maximum-likelihood-estimation-mle" class="title-slide slide level1 center"><h1>Maximum Likelihood Estimation (MLE)*</h1>

</section><section id="likelihood-function" class="slide level2"><h2>Likelihood Function</h2>
<ul>
<li>Maximum likelihood estimation is a method of finding <em>point estimators</em>.</li>
<li>Suppose <span class="math inline">\(y_i \stackrel{iid}{\sim} f(y|\theta)\)</span>
</li>
<li>The joint probability function of the data <span class="math inline">\((y_1, y_2, \dots, y_n)\)</span> is <span class="math display">\[f(y_1, y_2, \dots, y_n|\theta) = \prod_{i = 1}^nf(y_i|\theta)\]</span>
</li>
<li>When the function is viewed as a function of <span class="math inline">\(\theta\)</span>, with the data given, it is called the <strong>likelihood function</strong> <span class="math inline">\(L(\theta|{\bf y} = (y_1, y_2, \dots, y_n))\)</span>: <span class="math display">\[L(\theta|{\bf y}) =  \prod_{i = 1}^nf(y_i|\theta)\]</span>
</li>
<li>
<span class="math inline">\(L(\theta|{\bf y})\)</span> is <strong>not</strong> a probability or density function.</li>
</ul>
<aside class="notes"><ul>
<li>Maximum likelihood is a method of finding <em>point estimators</em>.</li>
<li>Sample independently from a population whose pmf/pdf is <span class="math inline">\(f(y|\theta)\)</span> with unknown <span class="math inline">\(\theta\)</span>.</li>
<li>The joint probability function of the data <span class="math inline">\((y_1, y_2, \dots, y_n)\)</span> is <span class="math display">\[f(y_1, y_2, \dots, y_n|\theta) = \prod_{i = 1}^nf(y_i|\theta)\]</span>
</li>
<li>When the function is viewed as a function of <span class="math inline">\(\theta\)</span>, with the data given, it is called the <strong>likelihood function</strong> <span class="math inline">\(L(\theta|{\bf y} = (y_1, y_2, \dots, y_n))\)</span>: <span class="math display">\[L(\theta) =  \prod_{i = 1}^nf(y_i|\theta)\]</span>
</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="likelihood-function-1" class="slide level2"><h2>Likelihood Function</h2>
<ul>
<li>For easier calculation and computation, we work with the <strong>log-likelihood function</strong> <span class="math display">\[\ell(\theta|{\bf y}) := \log L(\theta|{\bf y})\]</span>
</li>
</ul>
<div class="cell" data-layout-align="center">

</div>

<img data-src="./images/04-slr/unnamed-chunk-49-1.png" style="width:100.0%" class="r-stretch quarto-figure-center"><aside class="notes"><ul>
<li>For easier calculation and computation, we usually work with the <strong>log-likelihood function</strong> defined by <span class="math display">\[\ell(\theta|{\bf y}) := \log L(\theta|{\bf y})\]</span>
</li>
</ul><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="example-maximum-likelihood-estimation" class="slide level2"><h2>Example: Maximum Likelihood Estimation</h2>
<ul>
<li>Maximizing <span class="math inline">\(L(\theta)\)</span> with respect to <span class="math inline">\(\theta\)</span> yields the <strong>maximum likelihood estimator</strong> of <span class="math inline">\(\theta\)</span>, i.e., <span class="math display">\[\hat{\theta}_{ML} = \underset{\theta}{\arg \max} L(\theta) = \underset{\theta}{\arg \max} \log L(\theta)\]</span>
</li>
<li>
<strong>Intuition</strong>: Given the data <span class="math inline">\((y_1, y_2, \dots, y_n)\)</span>, we are finding a value of parameter <span class="math inline">\(\theta\)</span> so that the given data set is <strong>most likely to be sampled</strong>.</li>
</ul>
<div class="fragment">
<ul>
<li>Example: Suppose <span class="math inline">\(Y_1, Y_2, \dots, Y_n \stackrel{iid}{\sim} Bernoulli(\theta)\)</span>, where <span class="math inline">\(\theta\)</span>, the probability of success, is the <strong>unknown</strong> parameter to be estimated.</li>
</ul>
</div>
<div class="fragment">
<div class="question">
<p>What is the Bernoulli distribution?</p>
</div>
</div>
<div class="fragment">
<ul>
<li>The probability function of <span class="math inline">\(Y_i\)</span> is <span class="math inline">\(P(Y_i = y_i) = f(y_i) = \theta^{y_i}(1-\theta)^{1-y_i}\)</span> for <span class="math inline">\(y_i=0, 1\)</span>. <span class="math display">\[L(\theta) = \prod_{i = 1}^nf(y_i|\theta) = \prod_{i = 1}^n\theta^{y_i}(1-\theta)^{1-y_i} = \theta^{\sum_{i=1}^ny_i}(1-\theta)^{n-\sum_{i=1}^ny_i}\]</span>
</li>
</ul>
</div>
</section><section id="example-maximum-likelihood-estimation-1" class="slide level2"><h2>Example: Maximum Likelihood Estimation</h2>
<p><span class="math display">\[L(\theta) = \prod_{i = 1}^nf(y_i|\theta) = \prod_{i = 1}^n\theta^{y_i}(1-\theta)^{1-y_i} = \theta^{\sum_{i=1}^ny_i}(1-\theta)^{n-\sum_{i=1}^ny_i}\]</span></p>
<ul>
<li>
<p>Suppose <span class="math inline">\(n = 20\)</span> and <span class="math inline">\(\sum_{i=1}^{20}y_i = 12\)</span> from the sample data</p>
<ul>
<li><span class="math inline">\(L(\theta) = \theta^{12}(1-\theta)^{8}\)</span></li>
<li><span class="math inline">\(\log L(\theta) = 12 \log(\theta)+8\log(1-\theta)\)</span></li>
</ul>
</li>
<li><p>Fist order condition: <span class="math inline">\(\frac{d \, \log L(\theta)}{d \, \theta} = \frac{12}{\theta} - \frac{8}{1-\theta} = 0\)</span>.</p></li>
<li><p><span class="math inline">\(\hat{\theta}_{ML} = 12/20 = 0.6\)</span>.</p></li>
</ul>
<div class="fragment">
<ul>
<li>Given <span class="math inline">\(n = 20\)</span> and <span class="math inline">\(\sum_{i=1}^{20}y_i = 12\)</span>, <span class="math inline">\(\hat{\theta}_{ML} = 12/20 = 0.6\)</span> makes the data most possible.</li>
</ul>
</div>
</section><section id="example-maximum-likelihood-estimation-2" class="slide level2"><h2>Example: Maximum Likelihood Estimation</h2>
<ul>
<li>The estimated probability of successes <span class="math inline">\(\hat{\theta}_{ML}\)</span> is the sample proportion of successes <span class="math inline">\(\frac{\sum_{i=1}^n y_i}{n} = \frac{12}{20}\)</span>.</li>
</ul>

<img data-src="./images/04-slr/unnamed-chunk-50-1.png" style="width:100.0%" class="r-stretch quarto-figure-center"></section><section id="linear-regression-estimation-by-maximum-likelihood" class="slide level2"><h2>Linear Regression: Estimation by Maximum Likelihood</h2>
<!-- - If the distribution of the errors is known, the maximum likelihood estimation can be used. -->
<ul>
<li>
<span class="math inline">\(Y_i = \beta_0 + \beta_1X_i + \epsilon_i\)</span> with <span class="math inline">\(\epsilon_i \stackrel{iid}{\sim} N(0, \sigma^2)\)</span>. This means <span class="math inline">\(Y_i \stackrel{iid}{\sim} N(\beta_0 + \beta_1X_i, \sigma^2)\)</span>
</li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>Given data <span class="math inline">\(\{(x_i, y_i)\}_{i=1}^n\)</span>, <span class="math display">\[\small L(\beta_0, \beta_1, \sigma^2 \mid \{(x_i, y_i)\}_{i=1}^n) = \prod_{i=1}^nN(y_i \mid \beta_0 + \beta_1x_i, \sigma^2)\]</span> <span class="math display">\[\begin{align}
\small
\ell(\beta_0, \beta_1, \sigma^2 \mid \{(x_i, y_i)\}_{i=1}^n)
\small
&amp;= \sum_{i=1}^n\log N(y_i \mid \beta_0 + \beta_1x_i, \sigma^2) \\
\end{align}\]</span>
</li>
</ul>
</div><div class="column" style="width:40%;">
<p><span class="math display">\[\begin{align}
\small \quad \quad
    \left.\frac{\partial \ell}{\partial\beta_0}\right\vert_{\tilde{\beta}_0, \tilde{\beta}_1, \tilde{\sigma}^2} &amp; = 0\\
  \small \quad \quad
    \left. \frac{\partial \ell}{\partial\beta_1}\right\vert_{\tilde{\beta}_0, \tilde{\beta}_1, \tilde{\sigma}^2} &amp;= 0\\
  \small \quad \quad
    \left. \frac{\partial \ell}{\partial\sigma^2}\right\vert_{\tilde{\beta}_0, \tilde{\beta}_1, \tilde{\sigma}^2} &amp;= 0
\end{align}\]</span></p>
</div>
</div>
</section><section id="estimation-by-maximum-likelihood" class="slide level2"><h2>Estimation by Maximum Likelihood</h2>
<ul>
<li><span class="math inline">\(\color{red}{\tilde{\beta}_0 = \overline{y} - \tilde{\beta}_1\overline{x}} = b_0\)</span></li>
<li><span class="math inline">\(\color{red}{\tilde{\beta}_1 = \frac{\sum_{i=1}^n(x_i - \overline{x})y_i}{\sum_{i=1}^n(x_i - \overline{x})^2}} = b_1\)</span></li>
<li><span class="math inline">\(\color{red}{\tilde{\sigma}^2 = \frac{\sum_{i=1}^n(y_i - \tilde{\beta}_0 - \tilde{\beta}_1x_i)^2}{n}}\)</span></li>
<li>The MLE of <span class="math inline">\(\sigma^2\)</span> is <em>biased</em>.</li>
<li>In general, MLE have better statistical properties than LSE.</li>
<li>MLE requires a full distributional assumption whereas LSE does not.</li>
</ul>
<aside class="notes"><p>(Not a serious problem here though)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>

<img src="https://upload.wikimedia.org/wikipedia/commons/e/e8/Marquette_Golden_Eagles_logo.svg" class="slide-logo r-stretch"><div class="footer footer-default">
<p><a href="https://math4780-f23.github.io/website/">math4780-f23.github.io/website</a></p>
</div>
</section></section>
</div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="../site_libs/revealjs/dist/reveal.js"></script><!-- reveal.js plugins --><script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script><script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script><script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script><script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script><script src="../site_libs/revealjs/plugin/multiplex/socket.io.js"></script><script src="../site_libs/revealjs/plugin/multiplex/multiplex.js"></script><script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script><script src="../site_libs/revealjs/plugin/notes/notes.js"></script><script src="../site_libs/revealjs/plugin/search/search.js"></script><script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script><script src="../site_libs/revealjs/plugin/math/math.js"></script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'multiplex': {"secret":null,"id":"edf8770c6ad6e19f","url":"https://reveal-multiplex.glitch.me/"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1800,

        height: 1000,

        // Factor of the display size that should remain empty around the content
        margin: 5.0e-2,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          
          RevealSearch,
          RevealZoom
        ]
      });
    </script><script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script><script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>


</body></html>